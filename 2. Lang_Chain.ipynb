{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6343843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e9c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c333e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc3b5ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks to technologies such as the Internet and devices now available to people, we have increasingly greater access to larger quantities of information. However, people with ageing disabilities or intellectual disabilities, non-native speakers, and others have difficulties reading and understanding information. For this reason, it is essential to provide text simplification mechanisms when accessing information. Natural Language Processing methods can be applied to simplify textual content and improve understanding. These methods often use machine learning algorithms and models which require resources, such as corpora, to be trained and tested. This article presents the EASIER corpus, a resource that can be used to build lexical simplification methods to process Spanish domain-independent texts. The EASIER corpus is composed of 260 annotated documents with 8,155 words labelled as complex and 5,130 words with at least one proposed context-aware synonym associated. Expert linguists in easy-to-read and plain language guidelines have annotated the corpus based on their experience adapting texts for people with intellectual disabilities. Sixteen annotation guidelines that discriminate between complex and simple words have been defined to help other groups of experts to generate new annotations. Additionally, an inter-annotator agreement test was performed to validate the corpus, obtaining a Fleiss Kappa coefficient of 0.641. Furthermore, a qualitative evaluation was conducted with 45 users (including people with intellectual disabilities, elderly people, and a control audience). Complex word identification tasks achieved moderate results, but the synonyms proposed to replace complex words achieved almost perfect ratings. This resource has been integrated into the EASIER platform, a tool that helps people with cognitive impairments and intellectual disabilities to read and understand texts more easily.IntroductionInformation and communication technologies, especially the Internet, have transformed how we live and communicate. While millions of texts are produced every day, not all of these texts are easy to understand for everyone due to their complexity. Texts that contain unusual and complicated words can cause cognitive accessibility barriers for people with intellectual disabilities. In this sense, one solution can be to offer cognitively accessible interfaces and simplified text content, which benefit not only individuals with intellectual and learning disabilities but also deaf and deaf-blind individuals, the elderly, the illiterate and immigrants whose native language is different, among others. The need for simplified texts is becoming increasingly critical as the number of individuals with disabilities is growing due to the ageing population [1].Manual production of simplified texts is a non-trivial and, at the same time, time consuming task [2]. In this sense, there are methods that systematically produce simplified content. Natural Language Processing (NLP) and artificial intelligence provide methods to simplify texts promoting readability and understandability for people with intellectual disabilities.Some directives provide guidelines on making content more accessible for individuals with intellectual and learning disabilities. In this regard, the most important noteworthy initiatives are the Web Content Accessibility Guidelines (WCAG) [3], the Easy-to-Read guidelines [4–6], the Plain Language guidelines [7] and the document issued by the Cognitive and Learning Disabilities Accessibility Task Force (W3C-COGA TF) [8]. One specific guideline is frequently repeated in all these initiatives: use a simple lexicon. In addition, other guidelines indicate that providing synonyms for complex words is also beneficial. Therefore, providing simplified texts has been found to be helpful for people with intellectual disabilities from a lexical point of view.Lexical simplification is an essential part of text simplification based on machine learning and deep learning methods to replace specific words with simpler ones for a particular audience. Lexical simplification requires a Complex Word Identification (CWI) task to detect words that are considered difficult for a target audience. Once these words are identified, Substitute Generation/Selection (SG/SS) tasks must offer a more straightforward synonym. SG tasks focus on producing substitutes for a target word in all the contexts in which it may appear. On the other hand, SS tasks collect these substitutes and select those that best fit the context in which the target word was found [9].Although these methods have shown promising results, manually annotated data or corpora are required for training purposes. Unfortunately, for Spanish, few annotated texts are available. This lack of resources has become the motivation for this work.In this article, the EASIER corpus is presented (https://github.com/LURMORENO/EASIER_CORPUS). This corpus aims to support CWI and SG/SS tasks, two important processes in text simplification aimed at an audience with intellectual disabilities. This has been achieved through the assistance of an expert linguist in easy-to-read and plain language guidelines. Two additional experts and people with intellectual disabilities have evaluated the resulting corpus to ensure the quality of the data provided.The EASIER corpus has been integrated into the EASIER tool [10, 11] (https://github.com/LURMORENO/easier) (http://easier.hulat.uc3m.es/), that improves the readability and understandability of texts for users with intellectual disabilities.This article is structured as follows. The “Background” Section introduces previous work related to corpora used in simplification tasks. The “Method” Section describes the steps and resources used to develop the corpus as well as the annotation guidelines. The “Corpus Description” Section provides some statistics of the corpus; the “User Evaluation” Section describes the experiments with different types of users. Finally, the “Conclusions” Section presents some conclusions and future work.BackgroundIn 1996, the first automatic text simplification approach [12] performed a superficial analysis of texts to identify verbs and nouns in complex phrases. Syntactic simplification consists in identifying grammatical complexities in sentences and converting them into much simpler ones [13]. The case of lexical simplification, which is the focus of this work, consists of substituting words in a given phrase to make it simpler without modifying its syntactic structure in any way.The PSET project [14] aimed to create a system that performs lexical and syntactic procedures to assist people with aphasia in reading English newspaper texts. In Portuguese, the PorSimples project [15] developed technologies aimed at improving web content for people with low literacy levels by performing lexical/syntactic modifications and, at the same time, developing resources for this language, such as a parallel corpus with simplified sentences. For the French language, works based on parallel corpora such as the Alector corpus [16] have been presented, which focus on alleviating reading difficulties for people with low reading level or people with dyslexia. Additionally, French domain-specific resources have been proposed, such as the CLEAR corpus [17], which contains parallel instances of medical terms with their simplified version, aiming to alleviate the difficulty present in text with specialized content. The Simplext project [18, 19] worked on Spanish texts using a modular system for lexical and syntactic procedures to help people with cognitive disabilities. The FIRST project [20] was focused on developing language technologies to help autistic people, relying on a set of rules, images and dictionary searches for document simplification. Moreover, for people with intellectual disabilities, an accessible web e-mail client that performed text simplification was developed in the Able2Include project [21] to address web text accessibility in the context of e-mail communication. More recently, the authors in the EASIER project developed a web application that provides people with an easier way to improve the readability and comprehension of texts in Spanish. This work has been carried out with the objective of providing relevant data to improve lexical simplification [10, 22, 23].Text simplification has been approached from different perspectives: using rule-based or machine learning systems to identify and improve complex texts [24]. Currently, deep learning systems are being used to generate a simplified version of a given text in a kind of machine translation process, see [25] for a comprehensive state of the art in text simplification. No matter what type of system is being used, it is always necessary to have resources to build, train or adapt text simplification methods. Annotated and simplified corpora are an essential part of these resources in NLP systems development.Parallel corpora, which contain original texts together with their simplified versions, are very valuable resources for training text simplification algorithms, especially in languages with few resources, as is the case of Spanish. There are parallel corpora with aligned texts with a range of complexity levels; Table 1 shows some examples of relevant related resources in text simplification for English and Spanish.Table 1Text simplification resources for English/Spanish.The most common are corpora comprised of a set of original sentences and their simplified versions. The Simplext project provided new resources such, as a parallel corpus comprised of 200 news texts, including their original and simplified versions. Other examples are [26–28] in English, [29] in Portuguese, [30] in German, [31] in Italian and [18, 28, 32] in Spanish. A recent paper [33] presents an overview of parallel corpora for text simplification in different languages, which complements the contents of Table 1.Regarding lexical simplification, specific resources have been made available over the years. In English, SemEval-2012 [34] provided possible substitutes for a target word ranked in ascending order by their complexity, taking the context into consideration or based on the lexical substitution dataset [50], which focused on finding the best set of candidates for the substitution of a target word. Other resources were created using alignment methods. Horn et al. [37] created a collection of 500 sentences, which became a crowd‐sourced lexical substitution resource sampled from English Wikipedia and Simple English Wikipedia alignments. In Spanish, Baeza-Yates et al. [24] automatically created a database from the Spanish Open Thesaurus and the 5-gram Google Books Ngram Corpus. This resource was then extended in the work of Štajner et al. [46] by combining it with other resources such as OpenThesaurus (https://web.archive.org/) and EuroWordnet (https://archive.illc.uva.nl/EuroWordNet/). Also, certain resources were given additional specific tasks. For English CWI, in SemEval-2016 [51] a set of instances were presented, each of which had metadata associated with a target word labelled as either simple or complex. Some years later, the same task for English, Spanish, German and French was proposed [43], with the added value of performing classification for uni-words and multi-words. Recently, the ALEXSIS dataset [49] exploited the data from this task to create a new dataset containing simplicity-ranked substitutes for complex words. Also, a recent workshop [48] proposed a resource by challenging the participants to perform the CWI in academic content. Therefore, the proposed systems had to detect which technical words are commonly used in the domain and labelled them as simple words.Most of these resources have been labelled by annotators without knowledge about cognitive accessibility, easy-to-read and plain language guidelines. Also, people with disabilities are not taken into account in the annotation process as is indicated in the “Annotation method” column in Table 1. EASIER corpus addresses this gap providing support for the CWI task and searching the corresponding synonym aimed at people with cognitive impairments, such as the elderly and people with intellectual disabilities, among others. The EASIER corpus has been annotated by easy-to-read and plain language experts following a methodological approach that involves people with disabilities.MethodBefore explaining the methodology, recruitment of annotators, materials and instruments, it is important to mention that the experiments presented in this article have been reviewed to ensure that no confidential information is disclosed and has been approved in written form by an IRB at Universidad Carlos III de Madrid (IRB20_12) on October 28, 2020 and by the participants at subsequent dates.Selection of annotatorsThree annotators have taken part in corpus construction. One annotated the entire corpus (main annotator), while the other two annotated part of the corpus to calculate the Inter-Annotator Agreement (IAA). The three annotators are Spanish native speakers, expert linguists and specialists in easy-to-read and plain language guidelines. They have more than 15 years of experience transforming conventional texts into easy-to-read texts. They belong to Plena Inclusión (https://plenainclusionmadrid.org/) Madrid and Grupo Amas Fácil (https://amasfacil.org/), two organisations that work to offer resources adapted to people with intellectual and learning disabilities. It should be noted that these annotators manually adapted the texts following a methodology that involves people with intellectual disabilities throughout the process.MaterialsTwo hundred and sixty news articles from the “60 y más” magazine (http://www.revista60ymas.es/60mas_01/index.htm), ranging from beginning of 2019 until the first months of 2020, were randomly selected based on their length. News covered a range of different topics in the areas of current affairs, health, guides for seniors and news. Thus, the EASIER corpus is a domain-independent corpus. Each document had a similar length, and the corpus has an average of 15 sentences per document. This journal belongs to Imserso (https://www.imserso.es/imserso_01/index.htm), the Institute for the Elderly and Social Services in Spain. This group’s main objective is to promote the social integration of the elderly through information in Spanish.InstrumentsAnnotators used an annotation tool created as an extension for Google Chrome (https://github.com/ralarcong/EASIER_AnnotationTool). The authors have developed it to (a) select and deselect words that are considered complex or unusual in a given text and (b) propose simple, context-appropriate synonyms for the target word.The corpus construction methodology includes three steps following an iterative process (see Fig 1):Fig 1Corpus building methodology.Annotation Guidelines Definition. Based on the annotator’s experience and knowledge of easy-to-read and plain language guidelines, the main annotator establishes various annotation guidelines to detect complex words and suggest simple synonyms.Annotation Process. The annotator performs the analysis of the texts according to the annotation guidelines using the annotation tool.Annotation Guidelines Validation. In order to validate the annotation guidelines, an initial evaluation with the participation of people with intellectual disabilities of the set of texts annotated to date was performed. Once the documents have been fully annotated, the resulting corpus is described in the “Corpus description” Section. A portion of the data set is extracted and annotated by two other annotators to calculate IAA.The annotation process, which describes the steps of the methodology, is shown below.Annotation guidelines definitionThe main annotator defined the annotations guidelines and annotated complex words in texts accordingly. The terms given below should be annotated as complex terms:Words that are common in verbal communication but probably are unknown to the people under study. The Spanish linguistic frequency indexes (Gran Diccionario de Uso del Español Actual, Corpus CREA (https://corpus.rae.es/lfrecuencias.html), Corpus CORPES XXI (https://www.rae.es/banco-de-datos/corpes-xxi) [4, 6, 52–56] are the resources used to identify these words.The syllable configuration of a word should also be considered. When syllables are long or have more consonants, the effort needed to pronounce them could affect comprehension [6, 54, 56, 57].Long words that are difficult to read and pronounce such as “esternocleidomastoideo”, (sternocleidomastoid), represent difficulty in reading and pronunciation [6, 56].Technical jargon, for example, terms used in the medical or legal fields [4, 6, 55, 56].Abbreviations or acronyms when an explanation is not included in the document. For example, a document explaining the objectives of the WHO, but the expansion “World Health Organization” is not included in the text [4, 6, 55, 56, 58].Words in a language other than the main language of the document. Since EASIER’s target audience is the elderly and people with disabilities, it should not be assumed that they know other languages [4, 6, 56].Roman numerals [6, 56, 59].Idioms because they could have a double meaning that is difficult to understand, such as “cost an arm and a leg” which gives the sense of something expensive [6, 56].Metaphorical expressions because are hard to understand [4, 6, 56].Abstract terms which physical form cannot be perceived or imagined. For example, Terms such as “justice” or “emotion” are considered difficult to understand [4, 6, 56].Multi-word terms of different types [4, 6, 56]:\n",
      "Expressions constructed with complex words. For example, “key indicators” or “contractual resources”.Expressions including simple words whose more familiar meaning has been modified. For example, “social tourism” or “portfolio of services”.Complex expressions including complex and simple words whose most well-known meaning has been modified. For example, “strategic framework” or “inter-territorial council”.Common words whose most frequent meaning is modified by the context in which they are found (linked to polysemy). For example, the “active” word has two senses: (a) the portion of the population either with a job or looking for a job and (b) a person who likes to be active, being the most used the second one [6, 56].Percentages and mathematical expressions, for example, numbers expressing largequantities [4, 6, 56, 60].Adverbs ending in “-mente” (-ly) because of their prolonged pronunciation [6, 56].Collective nouns because are harder to understand than enumeration. For example, the concept “indumentaria” (clothing).Words that are obsolete or in disuse [56].The Table in S1 Table shows examples of selected uni-words or multi-words according to the criteria described in this section are provided.Annotation guidelines validationA quarter of the dataset was annotated to assess the initial set of annotation guidelines, and a set of experiments were carried out with people with cognitive disabilities belonging to the target group. The aim was to evaluate and refine the expert linguist’s annotation guidelines.The participants, the methodology and the results of this validation are explained below.Participants Some validation sessions were held in which people with disabilities are the validators to ensure that the adaptation is being done correctly. Eight people with mild intellectual disabilities (Group 1) and older people (Group 2), with five women and three men were chosen to participate in the initial evaluation. Of the five women, three were people with intellectual disabilities and two were elderly. In the group of men, two were people with intellectual disabilities, and one was an older adult. The validators’ age ranged from 25 to 86, seven with primary education and one with secondary schooling.Methodology The method used to validate easy reading texts by people with intellectual disabilities is supported by results reports from European projects such as the train2validate project (https://plenainclusionmadrid.org/train2validate/?lang=es), Pathways project (https://www.inclusion-europe.eu/pathways-2/), and complies with standards such as Guidance on making written text easy to read and easy to understand [61] and Easy to read. Guidelines and recommendations for elaborating documents [6]. This validation is organized in group sessions with a facilitator, support professional, and people with intellectual disabilities who participated as validator because they have reading comprehension difficulties. The validation session lasted three hours, including a twenty-minute break, and was moderated by a facilitator and our expert in easy-to-read who was annotating our corpus. The validators were provided with documents containing twenty-five complex words. These documents belong to the current affairs section (see Table 2), all framed within sentences and the corresponding synonyms. The moderator projected the document on a screen, then read each sentence aloud and asked the group whether they knew the adverse word or not and its meaning. This was an important step that allowed for assessing the participants’ comprehension capacity and clarifying the concepts if there were doubts. Each validator gave his or her opinion and was free to make comments as they saw fit. The moderator then read the synonyms and reread each sentence aloud, substituting each synonym’s adverse word. Finally, the validators commented on the meaning of each synonym, determined the most appropriate option and, if there were several synonyms, ordered them according to their comprehension criteria, which are as follows:Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Known for both groups: Every validator understands the meaning of the word.Explanation required: Every validator has an idea of the meaning of the word due to its context but at least one of them needs an explanation.Unknown: At least one validator does not know/understand the word.Results and discussion \n",
      "Table 2 shows a portion of the dataset used for evaluation. The human evaluation showed that most of the words represented a challenge for the participants to comprehend (84%), either because they were unfamiliar with said words or needed additional explanation by the moderators. This demonstrates moderate results regarding the quality of the corpus in the decision making of word complexity criteria. For the synonyms proposal, the validators responded well, showing a better understanding of the text with the proposed synonyms. However, users gave a different priority to the suggested synonyms. For example, they understood the word “alteraciones” (alterations) better than the word “irregularidades” (irregularities). Also, users experienced increased difficulty understanding when more than three synonyms were proposed. Thanks to the validation session, the need for several resources or elements to assist in understanding the meaning of a complex word was confirmed. In some cases, it was found that merely showing possible substitutions for a word was not enough for participants to fully understand it, as the user required additional information about the word, such as a definition or an example. This requirement reaffirms the objectives of the EASIER project within which this work is framed. In addition to satisfying the processes of lexical simplification (CWI, SG/SS), this project offers additional comprehension aids such as providing disambiguated definitions and pictograms [10, 62].Corpus descriptionA total of 260 documents were annotated with complex words, from which an average of 15 sentences per document was obtained. As a result, approximately 8,100 complex words were gathered. At the same time, it should be mentioned that more than 5,100 words, for which at least one synonym was proposed, were also obtained (see Table 3).Table 3EASIER corpus statistics.Two distinct datasets could be distinguished: one for Complex Word Identification (CWI) tasks and another for Substitute Generation/Selection (SG/SS) tasks. Each instance of the CWI dataset has six columns (See Table in S2 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the sentence for a particular word.The third column shows the sentence.The fourth and fifth columns show the offset of the target word.The sixth column shows the target word.The seventh column shows the correct label for the binary task (0: simple or 1: complex).For the second dataset, each instance has five columns (See Table in S3 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the target word.The third column shows the target word.The fourth column shows the sentence.The fifth column shows the suggested synonyms for the target word separated commas.EASIER corpus dataset evaluationIn order to determine how well an annotation task is defined, the IAA is used to show how individual annotators compare to each other. This has been done for the CWI adm SG/SS datasets as is explained below.Complex Word Identification (CWI) dataset inter-annotator agreement Two additional annotators performed the agreement. First, for the CWI dataset evaluation, the decision was made to evaluate the Fleiss Kappa coefficient since it is intended for assessments carried out between two or more annotators. However, to obtain a more in-depth analysis between scorers, the Cohen’s Kappa coefficient between each annotator has been evaluated.Following corpus annotation recommendations [63], to evaluate complex words’ annotation, 10% of the corpus was randomly extracted. As a result, 26 documents were obtained, from which 390 sentences to evaluate were obtained. As can be seen in Table 4, these metrics were extracted based on the POS tags, e.g., in the case “N” only metrics were calculated for the nouns of the corpus instances, while for “N—V—A”, they were calculated for the noun, verb and adverb tags as a whole (full evaluation can be found at https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS).Table 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.According to the analysis of results, a moderate result was obtained with a Fleiss Kappa coefficient of 0.641. The highest agreement was reached when analysing the multi-words since long words or phrases make it difficult to understand the message. On the other hand, interjections were considered to have lexical content in some cases. Therefore, these few instances are removed from the corpus.Substitute Generation/Selection (SG/SS) dataset evaluation Inspired by previous work [64–66], a scale-based methodology was used to evaluate the content of the synonym dataset. The original annotator proposed synonyms for a target word and did not assign labels for this dataset. Therefore, to evaluate this dataset and in order to verify the quality of the proposed synonyms, the two additional annotators were asked to assign two types of labels for each synonym: “0: synonym incorrectly defined” and “1: well-defined synonym”. To this end, 10% of the total number of instances were extracted in which the target word needed to have at least three proposed synonyms. As a result, a dataset of 513 target words was obtained together with their respective synonyms.\n",
      "Fig 2 shows that positive results were obtained, as evidenced by the clear difference between well-defined and incorrectly defined synonyms. Of the 1,026 synonyms reviewed, annotator 2 rated 987 synonyms as well-defined and 37 as incorrectly defined. In turn, annotator 3 rated 913 synonyms as well-defined and 113 as incorrectly defined. Subsequently, an analysis was carried out of the instances in which the synonyms were rated as incorrectly defined. It was found that in several cases, these words were qualified in this way due to the fact that, although they could fit in the context, they presented some ambiguity with regard to their meaning. An example of this is the word “salubrity” in the sentence “Tiempos en los que la salubridad era escasa.” (Times when salubrity was scarce). The well-defined replacements were “limpieza” (cleanliness) and “hygiene” (hygiene). However, the incorrectly defined replacement was “salud” (health), which may work within the context of the sentence but modifies its semantics.Fig 2Annotations between annotator 2 and 3.User evaluationIn this section, different experiments to validate the EASIER corpus are described including participants, materials, procedure, tasks and metrics used for each experimentation (also available at https://github.com/ralarcong/EASIERCORPUS_EVALUATION).ParticipantsA total of 45 participants were recruited for this experimental study. The inclusion criteria were people with cognitive disabilities that included people with mild cognitive impairments medically identified and older people who have cognitive problems due to age deterioration. In addition, people without disabilities as a control group were considered. The participants were recruited by the HULAT group (https://hulat.inf.uc3m.es/) to which the authors belong in collaboration with the AMAS group (https://www.fundacion-amas.org/), an organization that works to provide resources for people with intellectual disabilities.\n",
      "Table 5 shows an overview of the demographic information of the participants. The participants were divided into three groups: Group 1 represented 15 older people (33.3%), Group 2 represented 15 people with intellectual disabilities (33.3%) and Group 3 represented 15 control users (33.3%).Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).Across the entire population (all groups), the lowest number of participants corresponded to the age group between 34 and 44 years old with 10 participants (22%) and to participants over 71 years old with 7 participants (16%); on the other hand, the highest number of participants corresponded to the age group under 33 years old with 13 participants (29%) and to participants between 45 and 70 years old with 15 participants (33%).There was a small difference between the number of female (53%) and male (47%) people with 24 and 21 participants respectively.Regarding the educational level of the participants, the least number of participants were registered for people with no registered studies and people with a university degree with 3 (7%) and 10 (22%) participants respectively, and the majority had a high school level of education with 20 participants (44%), followed by primary level with 12 participants (27%).Finally, the reading level of the participants was evaluated through the number of books read per year, where the lowest number of participants was concentrated by 1 (2%) participant who read more than 12 books per year, 6 (13%) participants who read 6 to 12 books per year, followed by 9 (20%) participants who read 3 to 6 books per year. While the highest number of participants was presented by participants who do not read any book per year and participants who read 1 to 3 books per year with 15 (32%) and 14 (31%) participants respectively.MaterialsFor this experimental study 29 sentences of similar length were randomly extracted to evaluate the detected complex words and suggested replacements.ProcedureThe ethical committee of the Universidad Carlos III de Madrid (IRB20_12) approved this experimental study for people with and without disabilities on October 28, 2020. Participants were briefed on the purpose of the experiment and signed a consent form. In the case of people with intellectual disabilities, permission was obtained from their legal guardians. Next, participants were asked to complete a simple demographic questionnaire. Finally, each participant was asked to complete the tasks.The validation method used with people with intellectual disabilities was similar to the initial evaluation of the corpus, described in the Annotation Guidelines Validation section. The sessions were conducted at the AMAS Group facilities, where the researcher worked together with the AMAS facilitators. The rest of the tests were carried out at the university facilities, where the researcher worked directly with the user.The main steps were:Demographic questions about age, gender, education level and reading habits.Explanation and performance of task 1, referring to the CWI task.Explanation and performance of task 2, referring to remaining tasks in the lexical simplification process where a substitute is provided by the EASIER corpus.TasksTo evaluate the corpus, the following tasks were defined.Task 1 aims to measure the CWI task, i.e., the annotations of the corpus when discerning between complex and simple words. Each participant had to analyze 14 randomly selected sentences. In each sentence, the participant had to select single or multi-words that he/she judged to be complex or difficult to understand.Task 2 aims to measure the quality of the synonyms of the detected complex words, in order to determine whether the synonyms proposed by the EASIER corpus actually help to improve the cognitive comprehension of the texts. Each participant had to analyze 15 sentences, randomly selected. In each sentence, a detected complex word is highlighted and three candidate synonyms retrieved from the corpus are suggested. Thus, each participant had to analyze the sentences with each candidate and, as a next step, answer yes/no questions about whether the candidate helped to further understand the sentence.MeasuresThe measures in this experimentation were metrics used in the field of machine learning methods in order to compare the proposal with other related works [9, 38], which are the following:Accuracy: Represents the amount of correct identified words among all words.Precision: Amount of positives that are true.Recall: Amount of complex words correctly captured.F-1: The harmonic mean between precision and recallIn addition, different statistical metrics were used to obtain statistical significance, which are described in the next section.Results and discussionThis section gives results and discussions of the experiments described above. Likewise, this section is divided by the type of experimentation, complemented by subsequent analysis.\n",
      "Table 6 shows the scores for task 1. The results were moderate, obtaining an overall F1 score of 0.51 points, with better recall than precision with 0.69 and 0.57 respectively. By evaluating the proposal by groups, a difference in precision was observed between groups 1 (older people), 2 (people with intellectual disabilities) and 3 (control users) with 0.57, 0.59 and 0.55 points, respectively. In turn, regarding the recall, there was a minor difference between groups, with 0.68 points for Group 1, 0.69 points for Group 2 and 0.69 points for Group 3.Table 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\n",
      "Fig 3 shows a comparison of the precision scores between the study groups, where Group 2 (people with intellectual disabilities) achieved better results than Group 1 (older people) and Group 3 (control users). This indicates that the proposed CWI model achieved a higher number of quality predictions for people with intellectual disabilities than for older people and control users by getting a higher number of true positives. Although the difference in scores between the groups is minimal (about 0.02 points with Group 1 and 0.04 points with Group 3), this suggests that the proposal makes higher quality predictions for people with intellectual disabilities. Statistically comparing the precision between groups, the corpus was shown to be more beneficial for people with intellectual disabilities (Group 2) compared to older people in Group 1 (Wilcoxon test, P = 0.002) and control users in Group 3 (Wilcoxon test, P = 0.03).Fig 3Precision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.On the other hand, when analyzing recall scores, an increase was noted in comparison to precision. Fig 4 compares the recall scores of the study groups, where a greater dispersion of the data is clearly seen in the Group 1 and Group 2 than in the Group 3. This metric is important for this study as the corpus seeks to cover as many terms as possible when providing cognitive language support to people with intellectual disabilities and the elderly. In contrast to precision, the corpus provides greater coverage for older people (Group 1) compared to control users in Group 3 (Wilcoxon test, P = 0.02).Fig 4Recall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.In addition, Fig 5 presents the number of words that each participant considered complex, divided by groups. Most users in groups 1 and 3 are concentrated in the lower part of the graph where they detected a lower number of complex words (between 1 to 10 words across all sentences) and with additional values scattered across the graph. On the other hand, users with intellectual disabilities (Group 2), concentrated in a higher part of the graph by detecting a higher number of complex words, consequently supporting the precision and recall metrics described above.Fig 5Number of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Results achieved in CWI task do not seem very promising. We believe this could be related to ambiguity being greater in the case of open domain texts than in a restricted domain. Most research in NLP is devoted to solve the problem of ambiguity; NLP systems built to understand natural language only perform adequately in the domain for which they are designed and trained [67, 68], because the terminology is narrowed to a topic. Moreover, Gale et al. [69] showed that the sense of a target word is highly consistent within a given document (one meaning per discourse) and this reduces the number of synonyms of words in texts; this is comparable to the reduction of synonyms if texts of a restricted domain are considered. Nevertheless, simplification mechanisms are needed for information websites, such as news sites, that people access in search of information from a wide range of domains, hence the motivation for developing the Easier corpus. Moreover, experimentation with users is extraordinarily complex as it is carried out with subjective questions that measure how complex a word is for each person.Related to the second task, the quality of the synonym dataset was evaluated and, as described above, each participant was asked to evaluate three candidate substitutes for each of the 15 sentences of the study. Table 7 shows three types of results divided by groups, the first where the number of users who accepted at least one of the candidates presented for each sentence is recorded, the second which records the number of users who accepted at least two of the candidates presented for each sentence and the last one being the most rigorous one that counts the number of cases where all candidates were accepted by instance.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.Regarding the first result, an almost perfect percentage of acceptance was achieved for groups 1 (older people) and 2 (people with intellectual disabilities), with an acceptance percentage of 98% and 99% respectively. On the other hand, control users had a lower but close acceptance rate of 95%, mainly because this group of users does not represent the target user of the corpus. Therefore, this implies that the corpus greatly helps to reduce the level of complexity of the sentences, at least with a suggested candidate, and although a good acceptance was achieved in both groups, the group with intellectual disability was the one that received the most benefit. Later, more rigorous tests were carried out, where at least two candidates had to be accepted, obtaining in this case a higher percentage of acceptance of Group 1 than Group 2 with 72% and 69% respectively. Similarly, the acceptance rate of Group 3 dropped to 68%. Finally, when evaluating user responses in scenarios where all candidates were to be accepted, acceptance percentages of 57%, 52% and 32% were obtained for groups 1, 2 and 3, respectively.Concerning the second task, statistical significance tests were performed to understand these results, where it was confirmed that the synonyms provided by the corpus help the population made up of older people in Group 1 and people with intellectual disabilities in Group 2 (Fisher test, P = 0.03), complementing the results shown in Table 7.Later, these results were analyzed in relation to the education and reading level of each population. For example, the results showed statistically that the help of synonyms depended on the reading level of older users (Chi-square, P = 0.01).A similar example is shown in Fig 6 which divides the cases in which at least one substitution was accepted and the cases in which none was accepted, divided by group and educational level. For Group 1 (older people) there is a high number of substitutions accepted in participants with a high school level of education and a high number of acceptance for primary level of education for Group 2 (people with intellectual disabilities). It is worth mentioning that there is a higher concentration of participants with these levels of education for each group. For this same reason, there are cases in which the number of acceptances is low, as in the university level, which only had participants in Group 1.Fig 6Number of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.ConclusionsThis article introduces the EASIER corpus, which compiles a total of 260 Spanish documents of different topics annotated with complex words and synonyms. The EASIER corpus provides support for NLP methods to face lexical simplification in Complex Word Identification (CWI) and Substitute Generation/Selection (SG/SS) tasks. As a result, approximately 8,100 complex words were gathered. Additionally, it contains approximately 5,100 words for which at least one synonym was proposed. This corpus was built thanks to the annotation and evaluation of linguistic experts, who are specialised in easy-to-read and plain language guidelines. Sixteen annotation guidelines to discern between complex and simple words are also defined.The CWI dataset evaluation showed moderate IAA with a Fleiss Kappa coefficient of 0.641. On the other hand, an evaluation of this dataset with both target and control users, achieved a moderate overall F1-score of 0.51 points. However, since this corpus seeks to meet the needs of people with cognitive disabilities, greater importance was given to the recall metric, which was 0.68 and 0.69 points for older people and people with intellectual disabilities, respectively. Finally, a range of significance tests were also performed to confirm the corpus support between populations.Concerning the moderate IAA in complex word annotation tasks, it is important to highlight that tasks that require more interpretation of texts do not obtain a high agreement among annotators [63]. A high IAA is an indicator that the task is well defined and other annotators could replicate the work. Specifying if a word or phrase is a complex term is a subjective task, which influences the IAA value. In addition, the fact that an annotator has a high IAA certainly does not mean that the annotations are correct. It means that annotators have equally interpreted the guidelines. Bayerl and Paul [70] analyzed several factors that could influence IAA through different labeled corpora providing some recommendations to improve IAA like using few categories, recruiting annotators with the same level of domain expertise and providing training to them. To gain confidence in the integrity of annotations, they suggest having larger groups of annotators considering the criticality of tasks. In annotation tasks as the one described in this study, having expert and trained annotators in plain language and easy-to-read guidelines is essential.The evaluation of the SG/SS dataset showed positive results. Out of the 1,026 synonyms analysed, 987 were scored as well-defined by one annotator and 913 by the other one. The same people from the previous study evaluated a portion of the synonym dataset. Near-perfect results were obtained for cases where at least one synonym was accepted (out of 3), and moderate-to-good results were obtained for scenarios where two or more synonyms were accepted. As in the former dataset study, statistical tests were performed in order to confirm various hypotheses.This corpus is publicly available and currently being used in the EASIER platform. It has been created as a resource to assist both researchers and companies in carrying out simplification processes, with the added value that has been validated by people with disabilities.The EASIER corpus provides support for lexical simplification processes in a generic domain; lexical simplification of domain-independent texts is an extremely complex task, hence some of its moderate results. An extension of this resource will be developed for restricted domains (e.g., eGovernment, legal and health texts, among others) in future work. In addition, over the years, different scales have been proposed to evaluate complexity in texts [66], so the incorporation of new complexity scales (non-binary scale) will be evaluated.Supporting informationS1 TableAnnotation criteria examples. (PDF)Click here for additional data file.(1.2M, pdf)S2 TableCWI dataset instance examples. (PDF)Click here for additional data file.(517K, pdf)S3 TableSG/SS dataset instance examples. (PDF)Click here for additional data file.(1.2M, pdf)Funding StatementThis work has been supported by the R&D&i ACCESS2MEET (PID2020-116527RB-I0) project financed by MCIN AEI/10.13039/501100011033/. Additionally, this work is part of the \"Intelligent and interactive home care system for the mitigation of the COVID-19 pandemic\" project (PRTR-REACT UE) awarded by CAM. CONSEJERÍA DE EDUCACIÓN E INVESTIGACIÓN. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.Data AvailabilityEasier corpus available at https://github.com/LURMORENO/EASIER_CORPUS Annotators used an annotation tool created as an extension for Google Chrome: https://github.com/ralarcong/EASIER_AnnotationTool The evaluations carried out on the EASIER corpus can be consulted at: https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS.Article informationPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622PMCID: PMC10096182PMID: 37043424Rodrigo Alarcon, Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Validation, Writing – original draft, Writing – review & editing,#* Lourdes Moreno, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing,# and  Paloma Martínez, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing#Rodrigo Alarcon\n",
      "Computer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\n",
      "Find articles by Rodrigo AlarconLourdes Moreno\n",
      "Computer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\n",
      "Find articles by Lourdes MorenoPaloma Martínez\n",
      "Computer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\n",
      "Find articles by Paloma MartínezNatalia Grabar, Editor\n",
      "Computer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\n",
      "\n",
      "STL UMR8163 CNRS, FRANCE\n",
      "Corresponding author.#Contributed equally.Competing Interests: The authors have declared that no competing interests exist.* E-mail: se.m3cu.fni@nocralarReceived 2022 Jul 22; Accepted 2023 Mar 13.Copyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Articles from PLOS ONE are provided here courtesy of PLOSReferences1. Eurostat SE. Population projections in the EU; 2020. September. Available from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=People_in_the_EU_-_population_projections&oldid=497115#Population_projections.2. \n",
      "Saggion H. Automatic Text Simplification. vol. 10; 2017. doi: 10.1007/978-3-031-02166-4 [CrossRef] [Google Scholar]3. W3C. Web Content Accesibility Guidelines (WCAG); 2019. Available from: https://www.w3.org/WAI/standards-guidelines/wcag/.4. \n",
      "Freyhoff G, Hess G, Kerr L, Menzel E, Tronbacke B, Van Der Veken K. Make It Simple, European Guidelines for the Production of Easy-to-Read Information for People with Learning Disability for authors, editors, information providers, translators and other interested persons. International League of Societies for Persons with Mental Handicap European Association, Brussels. 1998;. [Google Scholar]5. Smith K, Hallam G, Ghosh SB. Guidelines for professional library/information educational programs-2012. IFLA Education and Training Section, IFLA, The Hague, available at: www.ifla.org/publications/guidelinesfor-professionallibraryinformationeducational-programs-2012 (accessed 25 August 2014). 2012;.6. UNE. Asociación Española de Normalización, UNE 153101:2018 (Easy to read. Guidelines and recommendations for the elaboration of documents); 2018. Available from: https://www.une.org/encuentra-tu-norma/busca-tu-norma/norma?c=N0060036.7. European-Union. How to write clearly; 2011. Available from: https://op.europa.eu/en/publication-detail/-/publication/c2dab20c-0414-408d-87b5-dd3c6e5dd9a5.8. W3C. Grupo de trabajo de accesibilidad para discapacidades cognitivas y de aprendizaje (COGA TF); 2020. Available from: https://www.w3.org/TR/coga-usable/.9. \n",
      "Paetzold GH, Specia L. A survey on lexical simplification. Journal of Artificial Intelligence Research. 2017;60:549–593. doi: 10.1613/jair.5526 [CrossRef] [Google Scholar]10. Moreno L, Alarcon R, Martínez P. EASIER system. Language resources for cognitive accessibility. 22nd International ACM SIGACCESS Conference on Computers and Accessibility (virtual). 2020;.11. \n",
      "Alarcon R, Moreno L, Martínez P. Lexical Simplification System to Improve Web Accessibility. IEEE Access. 2021;9:58755–58767. doi: 10.1109/ACCESS.2021.3072697 [CrossRef] [Google Scholar]12. \n",
      "Shardlow M. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications. 2014;4(1):58–70. doi: 10.14569/SpecialIssue.2014.040109 [CrossRef] [Google Scholar]13. \n",
      "Aranzabe MJ, De Ilarraza AD, Gonzalez-Dios I. Transforming complex sentences using dependency trees for automatic text simplification in Basque. Procesamiento del lenguaje natural. 2013;50:61–68. [Google Scholar]14. Carroll J, Minnen G, Canning Y, Devlin S, Tait J. Practical simplification of English newspaper text to assist aphasic readers. In: Proceedings of the AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology. Citeseer; 1998. p. 7–10.15. Aluísio S, Gasperin C. Fostering digital inclusion and accessibility: the PorSimples project for simplification of Portuguese texts. In: Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas; 2010. p. 46–53.16. Gala N, Tack A, Javourey-Drevet L, François T, Ziegler JC. Alector: A Parallel Corpus of Simplified French Texts with Alignments of Misreadings by Poor and Dyslexic Readers. In: Proceedings of the Twelfth Language Resources and Evaluation Conference. Marseille, France: European Language Resources Association; 2020. p. 1353–1361. Available from: https://aclanthology.org/2020.lrec-1.169.17. Grabar N, Cardon R. CLEAR—Simple Corpus for Medical French. In: Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA). Tilburg, the Netherlands: Association for Computational Linguistics; 2018. p. 3–9. Available from: https://aclanthology.org/W18-7002.18. Bott S, Saggion H. An unsupervised alignment algorithm for text simplification corpus construction. In: Proceedings of the Workshop on Monolingual Text-To-Text Generation; 2011. p. 20–26.19. \n",
      "Saggion H, Štajner S, Bott S, Mille S, Rello L, Drndarevic B. Making it simplext: Implementation and evaluation of a text simplification system for spanish. ACM Transactions on Accessible Computing (TACCESS). 2015;6(4):1–36. doi: 10.1145/2738046 [CrossRef] [Google Scholar]20. \n",
      "Barbu E, Martín-Valdivia MT, Martínez-Cámara E, Urena-López LA. Language technologies applied to document simplification for helping autistic people. Expert Systems with Applications. 2015;42(12):5076–5086. doi: 10.1016/j.eswa.2015.02.044 [CrossRef] [Google Scholar]21. Saggion H, Ferrés D, Sevens L, Schuurman I, Ripollés M, Rodríguez O. Able to read my mail: An accessible e-mail client with assistive technology. In: Proceedings of the 14th International Web for All Conference; 2017. p. 1–4.22. Alarcon R, Moreno López L, Segura Bedmar I, Martínez Fernández P. Lexical simplification approach using easy-to-read resources. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2019;.23. Alarcon R, Moreno L, Martínez P. Word-Sense disambiguation system for text readability. In: 9th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion; 2020. p. 147–152.24. Baeza-Yates R, Rello L, Dembowski J. Cassa: A context-aware synonym simplification algorithm. In: Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies; 2015. p. 1380–1385.25. \n",
      "Al-Thanyyan SS, Azmi AM. Automated Text Simplification: A Survey. ACM Comput Surv. 2021;54(2). doi: 10.1145/3442695 [CrossRef] [Google Scholar]26. Petersen SE, Ostendorf M. Text simplification for language learners: a corpus analysis. In: Workshop on Speech and Language Technology in Education. Citeseer; 2007.27. Pellow D, Eskenazi M. An open corpus of everyday documents for simplification tasks. In: Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR); 2014. p. 84–93.28. \n",
      "Xu W, Callison-Burch C, Napoles C. Problems in current text simplification research: New data can help. Transactions of the Association for Computational Linguistics. 2015;3:283–297. doi: 10.1162/tacl_a_00139 [CrossRef] [Google Scholar]29. \n",
      "Caseli HM, Pereira TF, Specia L, Pardo TA, Gasperin C, Aluísio SM. Building a Brazilian Portuguese parallel corpus of original and simplified texts. Advances in Computational Linguistics, Research in Computer Science. 2009;41:59–70. [Google Scholar]30. Klaper D, Ebling S, Volk M. Building a German/simple German parallel corpus for automatic text simplification. Zurich Open Repository and Archive. 2013;.31. Brunato D, Dell’Orletta F, Venturi G, Montemagni S. Design and annotation of the first Italian corpus for text simplification. In: Proceedings of The 9th Linguistic Annotation Workshop; 2015. p. 31–41.32. Štajner S. New data-driven approaches to text simplification; 2016.33. \n",
      "Brunato D, Dell’Orletta F, Venturi G. Linguistically-Based Comparison of Different Approaches to Building Corpora for Text Simplification: A Case Study on Italian. Frontiers in Psychology. 2022;13. doi: 10.3389/fpsyg.2022.707630\n",
      " [PMC free article] [PubMed] [CrossRef] [Google Scholar]34. Specia L, Jauhar SK, Mihalcea R. Semeval-2012 task 1: English lexical simplification. In: * SEM 2012: The First Joint Conference on Lexical and Computational Semantics–Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012); 2012. p. 347–355.35. \n",
      "Sharoff S. Open-source corpora: Using the net to fish for linguistic data. International journal of corpus linguistics. 2006;11(4):435–462. doi: 10.1075/ijcl.11.4.05sha [CrossRef] [Google Scholar]36. De Belder J, Moens MF. A dataset for the evaluation of lexical simplification. In: International Conference on Intelligent Text Processing and Computational Linguistics. Springer; 2012. p. 426–437.37. Horn C, Manduca C, Kauchak D. Learning a lexical simplifier using Wikipedia. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers); 2014. p. 458–463.38. Paetzold G, Specia L. Benchmarking Lexical Simplification Systems. In: Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16). Portorŏz, Slovenia: European Language Resources Association (ELRA); 2016. p. 3074 -3080. Available from: https://aclanthology.org/L16-1491.39. Paetzold G, Specia L. Unsupervised lexical simplification for non-native speakers. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 30; 2016.40. Kauchak D. Improving text simplification language modeling using unsimplified text data. In: Proceedings of the 51st annual meeting of the association for computational linguistics (volume 1: Long papers); 2013. p. 1537–1546.41. Zhu Z, Bernhard D, Gurevych I. A monolingual tree-based translation model for sentence simplification. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010); 2010. p. 1353–1361.42. Kajiwara T, Komachi M. Building a monolingual parallel corpus for text simplification using sentence similarity based on alignment between word embeddings. In: Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers; 2016. p. 1147–1158.43. Yimam SM, Štajner S, Riedl M, Biemann C. Multilingual and cross-lingual complex word identification. In: Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017; 2017. p. 813–822.44. Zhang X, Lapata M. Sentence simplification with deep reinforcement learning. arXiv preprint arXiv:170310931. 2017;.45. Woodsend K, Lapata M. Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming. In: Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. Edinburgh, Scotland, UK.: Association for Computational Linguistics; 2011. p. 409–420. Available from: https://aclanthology.org/D11-1038.46. \n",
      "Štajner S, Saggion H, Ponzetto SP. Improving lexical coverage of text simplification systems for Spanish. Expert Systems with Applications. 2019;118:80–91. doi: 10.1016/j.eswa.2018.08.034 [CrossRef] [Google Scholar]47. Alva-Manchego F, Martin L, Bordes A, Scarton C, Sagot B, Specia L. ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. arXiv preprint arXiv:200500481. 2020;.48. Ortiz-Zambranoa JA, Montejo-Ráezb A. Overview of ALexS 2020: First Workshop on Lexical Analysis at SEPLN. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2020;.49. Ferrés D, Saggion H. ALEXSIS: A Dataset for Lexical Simplification in Spanish; 2022. [PMC free article] [PubMed]50. \n",
      "McCarthy D, Navigli R. The English lexical substitution task. Language resources and evaluation. 2009;43(2):139–159. doi: 10.1007/s10579-009-9084-1 [CrossRef] [Google Scholar]51. Paetzold G, Specia L. Semeval 2016 task 11: Complex word identification. In: Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016); 2016. p. 560–569.52. \n",
      "Anula A. Lecturas adaptadas a la enseñanza del español como L2: variables lingüísticas para la determinación del nivel de legibilidad. La evaluación en el aprendizaje y la enseñanza del español como LE L. 2008;2:162–170. [Google Scholar]53. Gunning R, et al. Technique of clear writing. 1952;.54. \n",
      "Kincaid J, Fishburn R, Rogers R, Chissom B. Derivation of new readability formulas for Navy enlisted personnel (Research Branch Report 8-75). Memphis, TN: Naval Air Station, Millington, Tennessee. 1975;40. [Google Scholar]55. W3C. WCAG 2.1; 2018. Available from: https://www.w3.org/TR/WCAG21/.56. Muñoz ÓG. Lectura fácil: métodos de redacción y evaluación. Real patronato sobre discapacidad; 2012.57. \n",
      "Drndarevic B, Saggion H. Reducing text complexity through automatic lexical simplification: an empirical study for Spanish. Procesamiento del lenguaje natural. 2012;49:13–20. [Google Scholar]58. \n",
      "Aldridge MD. Writing and designing readable patient education materials. Nephrology Nursing Journal. 2004;31(4):373–377.  [PubMed] [Google Scholar]59. \n",
      "Baker SJ. Who can read consumer product information?\n",
      "The Australian Journal of Hospital Pharmacy. 1997;27(2):126–131. doi: 10.1002/jppr1997272126 [CrossRef] [Google Scholar]60. \n",
      "Bautista S, Saggion H. Can Numerical Expressions Be Simpler?\n",
      "Implementation and Demostration of a Numerical Simplification System for Spanish. In: LREC; 2014. p. 956–962. [Google Scholar]61. ISO/IEC. ISO/IEC DIS 23859-1 Information technology — User interfaces — Part 1: Guidance on making written text easy to read and easy to understand; 2022.62. Moreno L, Alarcon R, Martínez P. Designing and Evaluating a User Interface for People with Cognitive Disabilities. In: Proceedings of the XXI International Conference on Human Computer Interaction; 2021. p. 1–8.63. \n",
      "Pustejovsky J, Stubbs A. Natural Language Annotation for Machine Learning: A guide to corpus-building for applications. “O’Reilly Media, Inc.”; 2012. [Google Scholar]64. Yu CH, Miller RC. Enhancing web page readability for non-native readers. In: Proceedings of the sIGCHI conference on human factors in computing systems; 2010. p. 2523–2532.65. Alonzo O, Seita M, Glasser A, Huenerfauth M. Automatic text simplification tools for deaf and hard of hearing adults: Benefits of lexical simplification and providing users with autonomy. In: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems; 2020. p. 1–13.66. Shardlow M, Cooper M, Zampieri M. CompLex — A New Corpus for Lexical Complexity Prediction from Likert Scale Data. In: Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI). Marseille, France: European Language Resources Association; 2020. p. 57–62. Available from: https://aclanthology.org/2020.readi-1.9.67. \n",
      "Cambria E, White B. Jumping NLP Curves: A Review of Natural Language Processing Research. IEEE Computational Intelligence Magazine. 2014;9(2):48–57. doi: 10.1109/MCI.2014.2307227 [CrossRef] [Google Scholar]68. \n",
      "Hirschberg J, Manning CD. Advances in natural language processing. Science. 2015;349(6245):261–266. doi: 10.1126/science.aaa8685\n",
      " [PubMed] [CrossRef] [Google Scholar]69. \n",
      "Gale WA, Church K, Yarowsky D. One sense per discourse. In: Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February; \n",
      "23–26, 1992; 1992. [Google Scholar]70. \n",
      "Bayerl PS, Paul KI. What determines inter-coder agreement in manual annotations? A meta-analytic investigation. Computational Linguistics. 2011;37(4):699–725. doi: 10.1162/COLI_a_00074 [CrossRef] [Google Scholar]Table 1Text simplification resources for English/Spanish.ResourceAnnotated textSizeLanguage: English (EN) Spanish (ES)Annotation methodSimple English WikipediaA simplified version of regular Wikipedia183,000 content pages to dateENPages edited by 1,203 active usersSemEval 2012 [34]English Internet Corpus [35]2,010 instances of simplicity rankingsENNative English speakersLSeval [36]English Internet Corpus [35]430 instances of simplicity rankingsEN46 Amazon Mechanical Turk (turkers), 9 PHD studentsLexMTurk [37]Wikipedia500 instances with target complex words and simpler synonymsEN50 Turkish English speakingBenchLS [38]Compilation of LSeval and LexMTurk929 instances with an average of 7 candidates per complex wordENCorrected and filtered by English speakersNNSeval [39]Filtered version of BenchLS239 instancesENNon-native english speakersWikipedia—Simple WikipediaSimple English Wikipedia167,689 aligned sentencesENLanguage modelling [40]PWKP (WikiSmall) [41]Wikipedia and Simple Wikipedia108,016 aligned sentencesENStatistical machine translationSimplext [19]News texts200 aligned news textsESHuman editors trained in easy-to-read guidelinesSS Corpus [42]Wikipedia and Simple Wikipedia492,993 aligned sentencesENUnsupervised methodNewsela [28]News articlesParallel simple-complex articles with 11-grade levelsEN, ESManually produced by professional editorsRANLP 2017 [43]Wikipedia14,280 instances with target complex wordsEN, ES54 turkers (Native and non-native speakers)WikiLarge [44]WikiSmall, Aligned sentences pairs [40, 45]2,000 for dev, 359 for test, 296,402 for trainingENCombination of previously created simplification corporaPPDB-S/M [46]PPDB5,709 unigrams for S size, 15,524 unigrams for M sizeESBuilt by filtering and ordering paraphrases pairs from the paraphrases database (PPDB)CASSA [46]CASSA dataset5,640,694 5-gramsESGenerated by extracting all unique 5-grams pairs from CASSA resourceASSET [47]TurkCorpus extension23,590 human simplifications associated with 2,359 sentences from TurkCorpusENAmazon Mechanical TurkVYTEDU-CW) [48]Transcripts of academic videos9,175 words, 723 annotated as complexES430 annotators studentsALEXSIS [49]RANLP 2017 datasets381 instances with an average of 10.28 substitutes per instanceESprolific.co annotatorsOpen in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 1Open in a separate windowCorpus building methodology.Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Target WordSynonymsConclusionEtiquetado (Labelling)Letrero (sign), inscripción (inscription), rótulo (banner)Explanation required for both groupsEtiqueta (formal/label)Ceremonia (ceremony), protocolo (protocol)Explanation required for Group 1Known Group 2Envasados (packaged)Empaquetados (packaging)Known by both groupsA granel (in bulk)Suelto (loose), sin envase (without packaging)Known for both groupsOn-line (Online)en línea (online), conectado a Internet (connected to the Internet)Known by Group 1Explanation required for Group 2Comensales (diners)Invitados (guests)Unknown by Group 1Known by Group 1Saludables (salubrious)Sanos (healthy), beneficiosos (beneficial)Explanation required for both groupsCopiosa (copious)Abundante (abundant)Unknown by both groupsCrudos (raw)sin cocinar (not cooked)Known by both groupsDenominación (denomination)Nombre (name)Explanation required for both groupsReclamar (claim)Demandar (sue), quejarse (complain), exigir (demand)Explanation required for both groupsIrregularidades (irregularities)Anomalía (anomaly), alteración (alteration), variación (variation)Unknown by both groupsÓptimas (optimum)Buenas (good), excelentes (excellent)Explanation required by both groupsEmbalaje (packaging)Envase (container), envoltorio (wrapping)Known for both groupsÍntegro (exhaustive)Entero (whole), completo (complete), intacto (intact)Known for both groupsConsumidor (consumer)Comprador (buyer/purchaser), cliente (client), usuario (user)Explanation required for Group 1Known Group 2Provisional (provisional)Temporales (temporary)Unknown for both groupsConsejo (Council)Asambleas (assembly), juntas (board), comisiones (commission/committee)Known for both groupsProporcionar (provide)Dar (give), proporcionar (provide)Known for both groupsCiudadanía (citizens)Sociedad (society), población (populace), nacionalidad (nationality)Known for both groupsVeraz (veracious)Real (real), cierta (certain), verdadera (true)Unknown by both groupsEficacia (efficiency)Utilidad (usefulness), efectividad (effectiveness)Unknown by both groupsContrastar (contrast)Comprobada (proven), comparada (compared), verificada (verified)Unknown for both groupsSoporte (base)Base (basis), fundamento (foundation), apoyo (support)Unknown for both groupsEvidencias (evidence)Certeza (certainty), seguridad (security), prueba (proof), demostración (demonstration)Known for both groupsOpen in a separate windowTable 3EASIER corpus statistics.EASIERDocuments260Sentences3,778Words134,528Average number of sentences per document15Average number of tokens per document517Total instances for CWI44,975Complex Words8,155Total instances for SG/SS5,130Proposed synonyms7,892Average of complex Words per document30Average of proposed synonyms per document29Complex Words with at least one substitute5,130Open in a separate windowTable 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.POSTAGCohen’s Kappa (Rater 1–2)Cohen’s Kappa (Rater 1–3)Cohen’s Kappa (Rater 2–3)Fleiss Kappa\n",
      "N\n",
      "0.47500.41140.57110.484\n",
      "V\n",
      "0.40820.52180.43850.454\n",
      "A\n",
      "0.20110.19420.46400.31\n",
      "I\n",
      "0.50020.15450.26580.3\n",
      "PN\n",
      "0.22630.24410.53380.347\n",
      "N—V\n",
      "0.46670.43650.55860.487\n",
      "N—V—A\n",
      "0.46280.43740.56020.487\n",
      "N—V—I\n",
      "0.46890.43420.55590.486\n",
      "N—V—I—PN\n",
      "0.43300.42280.55300.471\n",
      "N—V—M\n",
      "0.64550.60790.67280.641\n",
      "N—V—A—M\n",
      "0.64220.60940.67390.641\n",
      "N—V—I—M\n",
      "0.64650.60600.67070.64\n",
      "N—V—I—PN—M\n",
      "0.60670.59260.65970.619Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 2Open in a separate windowAnnotations between annotator 2 and 3.Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).FeaturesGroup 1Group 2Group 3All participantsN = 15%N = 15%N = 15%N = 45%\n",
      "Age\n",
      "71+7(47)----7(16)45–708(53)4(27)3(20)15(33)34–44--5(33)5(33)10(22)33 or younger--6(40)7(47)13(29)\n",
      "Gender\n",
      "Male7(47)6(40)8(53)21(47)Female8(53)9(60)7(47)24(53)\n",
      "Education (Highest completed)\n",
      "None1(7)2(13)--3(7)Primary school5(33)7(47)--12(27)High school9(60)6(40)5(33)20(44)University education----10(67)10(22)\n",
      "Reading experience (books per year)\n",
      "None3(20)9(60)3(20)15(33)1–35(33)3(20)6(40)14(31)3–64(27)1(7)4(27)9(20)6–123(20)2(13)1(7)6(13)12+----1(7)1(2)Open in a separate windowTable 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\n",
      "GROUP 1\n",
      "\n",
      "GROUP 2\n",
      "\n",
      "GROUP 3\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "10.570.780.520.40160.560.520.650.40310.560.520.590.4220.580.780.530.42170.630.590.770.54320.600.550.730.4730.680.740.650.63180.600.550.730.47330.590.550.730.4640.770.800.750.75190.590.550.690.47340.590.540.710.4450.700.740.680.67200.610.570.700.51350.590.550.730.4660.610.700.570.51210.590.560.580.53360.560.510.780.3770.580.780.530.42220.650.610.700.58370.710.700.720.7080.560.780.510.37230.590.560.600.53380.580.530.780.4290.590.680.540.45240.650.610.770.56390.570.520.680.42100.560.580.510.40250.650.610.750.57400.550.500.530.37110.630.800.580.52260.660.620.780.58410.630.590.700.54120.590.650.540.46270.640.610.690.58420.590.540.790.43130.530.510.510.48280.670.640.750.62430.560.520.650.40140.560.780.510.37290.650.610.770.56440.630.590.770.54150.630.730.590.53300.620.590.650.56450.590.540.710.44\n",
      "GROUP 1 SCORES\n",
      "\n",
      "GROUP 2 SCORES\n",
      "\n",
      "GROUP 3 SCORES\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "\n",
      "ID\n",
      "\n",
      "AC\n",
      "\n",
      "PR\n",
      "\n",
      "RC\n",
      "\n",
      "F-1\n",
      "ALL0.610.570.680.51ALL0.620.590.690.54ALL0.590.550.690.47\n",
      "OVERALL SCORE\n",
      "\n",
      "ACURACCY\n",
      "\n",
      "PRECISION\n",
      "\n",
      "RECALL\n",
      "\n",
      "F1\n",
      "0.610.570.690.51Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 3Open in a separate windowPrecision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 4Open in a separate windowRecall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 5Open in a separate windowNumber of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.At least one candidate ranked as correctAt least two candidates ranked as correctAll candidates ranked as correctSentence-IDGrp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)S1151515111213795S21515148107773S31515141099884S4151515121012878S51415141211108105S61515151111141199S7141514101110872S814151310115782S9151414111011875S1015151513121110105S111514141211131086S121515151211131097S1314151410107984S141515139118954S151514141169953\n",
      "MEAN\n",
      "14.7314.8014.2010.8010.4010.138.67.84.8\n",
      "ACCEPTANCE (%)\n",
      "989995726968575232Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi: 10.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 6Open in a separate windowNumber of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[2811:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c465982",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_doc=docs[0].page_content[2811:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2da06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks to technologies such as the Internet and devices now available to people, we have increasingly greater access to larger quantities of information. However, people with ageing disabilities or intellectual disabilities, non-native speakers, and others have difficulties reading and understanding information. For this reason, it is essential to provide text simplification mechanisms when accessing information. Natural Language Processing methods can be applied to simplify textual content and improve understanding. These methods often use machine learning algorithms and models which require resources, such as corpora, to be trained and tested. This article presents the EASIER corpus, a resource that can be used to build lexical simplification methods to process Spanish domain-independent texts. The EASIER corpus is composed of 260 annotated documents with 8,155 words labelled as complex and 5,130 words with at least one proposed context-aware synonym associated. Expert linguists in easy-to-read and plain language guidelines have annotated the corpus based on their experience adapting texts for people with intellectual disabilities. Sixteen annotation guidelines that discriminate between complex and simple words have been defined to help other groups of experts to generate new annotations. Additionally, an inter-annotator agreement test was performed to validate the corpus, obtaining a Fleiss Kappa coefficient of 0.641. Furthermore, a qualitative evaluation was conducted with 45 users (including people with intellectual disabilities, elderly people, and a control audience). Complex word identification tasks achieved moderate results, but the synonyms proposed to replace complex words achieved almost perfect ratings. This resource has been integrated into the EASIER platform, a tool that helps people with cognitive impairments and intellectual disabilities to read and understand texts more easily.IntroductionInformation and communication technologies, especially the Internet, have transformed how we live and communicate. While millions of texts are produced every day, not all of these texts are easy to understand for everyone due to their complexity. Texts that contain unusual and complicated words can cause cognitive accessibility barriers for people with intellectual disabilities. In this sense, one solution can be to offer cognitively accessible interfaces and simplified text content, which benefit not only individuals with intellectual and learning disabilities but also deaf and deaf-blind individuals, the elderly, the illiterate and immigrants whose native language is different, among others. The need for simplified texts is becoming increasingly critical as the number of individuals with disabilities is growing due to the ageing population [1].Manual production of simplified texts is a non-trivial and, at the same time, time consuming task [2]. In this sense, there are methods that systematically produce simplified content. Natural Language Processing (NLP) and artificial intelligence provide methods to simplify texts promoting readability and understandability for people with intellectual disabilities.Some directives provide guidelines on making content more accessible for individuals with intellectual and learning disabilities. In this regard, the most important noteworthy initiatives are the Web Content Accessibility Guidelines (WCAG) [3], the Easy-to-Read guidelines [4–6], the Plain Language guidelines [7] and the document issued by the Cognitive and Learning Disabilities Accessibility Task Force (W3C-COGA TF) [8]. One specific guideline is frequently repeated in all these initiatives: use a simple lexicon. In addition, other guidelines indicate that providing synonyms for complex words is also beneficial. Therefore, providing simplified texts has been found to be helpful for people with intellectual disabilities from a lexical point of view.Lexical simplification is an essential part of text simplification based on machine learning and deep learning methods to replace specific words with simpler ones for a particular audience. Lexical simplification requires a Complex Word Identification (CWI) task to detect words that are considered difficult for a target audience. Once these words are identified, Substitute Generation/Selection (SG/SS) tasks must offer a more straightforward synonym. SG tasks focus on producing substitutes for a target word in all the contexts in which it may appear. On the other hand, SS tasks collect these substitutes and select those that best fit the context in which the target word was found [9].Although these methods have shown promising results, manually annotated data or corpora are required for training purposes. Unfortunately, for Spanish, few annotated texts are available. This lack of resources has become the motivation for this work.In this article, the EASIER corpus is presented (https://github.com/LURMORENO/EASIER_CORPUS). This corpus aims to support CWI and SG/SS tasks, two important processes in text simplification aimed at an audience with intellectual disabilities. This has been achieved through the assistance of an expert linguist in easy-to-read and plain language guidelines. Two additional experts and people with intellectual disabilities have evaluated the resulting corpus to ensure the quality of the data provided.The EASIER corpus has been integrated into the EASIER tool [10, 11] (https://github.com/LURMORENO/easier) (http://easier.hulat.uc3m.es/), that improves the readability and understandability of texts for users with intellectual disabilities.This article is structured as follows. The “Background” Section introduces previous work related to corpora used in simplification tasks. The “Method” Section describes the steps and resources used to develop the corpus as well as the annotation guidelines. The “Corpus Description” Section provides some statistics of the corpus; the “User Evaluation” Section describes the experiments with different types of users. Finally, the “Conclusions” Section presents some conclusions and future work.BackgroundIn 1996, the first automatic text simplification approach [12] performed a superficial analysis of texts to identify verbs and nouns in complex phrases. Syntactic simplification consists in identifying grammatical complexities in sentences and converting them into much simpler ones [13]. The case of lexical simplification, which is the focus of this work, consists of substituting words in a given phrase to make it simpler without modifying its syntactic structure in any way.The PSET project [14] aimed to create a system that performs lexical and syntactic procedures to assist people with aphasia in reading English newspaper texts. In Portuguese, the PorSimples project [15] developed technologies aimed at improving web content for people with low literacy levels by performing lexical/syntactic modifications and, at the same time, developing resources for this language, such as a parallel corpus with simplified sentences. For the French language, works based on parallel corpora such as the Alector corpus [16] have been presented, which focus on alleviating reading difficulties for people with low reading level or people with dyslexia. Additionally, French domain-specific resources have been proposed, such as the CLEAR corpus [17], which contains parallel instances of medical terms with their simplified version, aiming to alleviate the difficulty present in text with specialized content. The Simplext project [18, 19] worked on Spanish texts using a modular system for lexical and syntactic procedures to help people with cognitive disabilities. The FIRST project [20] was focused on developing language technologies to help autistic people, relying on a set of rules, images and dictionary searches for document simplification. Moreover, for people with intellectual disabilities, an accessible web e-mail client that performed text simplification was developed in the Able2Include project [21] to address web text accessibility in the context of e-mail communication. More recently, the authors in the EASIER project developed a web application that provides people with an easier way to improve the readability and comprehension of texts in Spanish. This work has been carried out with the objective of providing relevant data to improve lexical simplification [10, 22, 23].Text simplification has been approached from different perspectives: using rule-based or machine learning systems to identify and improve complex texts [24]. Currently, deep learning systems are being used to generate a simplified version of a given text in a kind of machine translation process, see [25] for a comprehensive state of the art in text simplification. No matter what type of system is being used, it is always necessary to have resources to build, train or adapt text simplification methods. Annotated and simplified corpora are an essential part of these resources in NLP systems development.Parallel corpora, which contain original texts together with their simplified versions, are very valuable resources for training text simplification algorithms, especially in languages with few resources, as is the case of Spanish. There are parallel corpora with aligned texts with a range of complexity levels; Table 1 shows some examples of relevant related resources in text simplification for English and Spanish.Table 1Text simplification resources for English/Spanish.The most common are corpora comprised of a set of original sentences and their simplified versions. The Simplext project provided new resources such, as a parallel corpus comprised of 200 news texts, including their original and simplified versions. Other examples are [26–28] in English, [29] in Portuguese, [30] in German, [31] in Italian and [18, 28, 32] in Spanish. A recent paper [33] presents an overview of parallel corpora for text simplification in different languages, which complements the contents of Table 1.Regarding lexical simplification, specific resources have been made available over the years. In English, SemEval-2012 [34] provided possible substitutes for a target word ranked in ascending order by their complexity, taking the context into consideration or based on the lexical substitution dataset [50], which focused on finding the best set of candidates for the substitution of a target word. Other resources were created using alignment methods. Horn et al. [37] created a collection of 500 sentences, which became a crowd‐sourced lexical substitution resource sampled from English Wikipedia and Simple English Wikipedia alignments. In Spanish, Baeza-Yates et al. [24] automatically created a database from the Spanish Open Thesaurus and the 5-gram Google Books Ngram Corpus. This resource was then extended in the work of Štajner et al. [46] by combining it with other resources such as OpenThesaurus (https://web.archive.org/) and EuroWordnet (https://archive.illc.uva.nl/EuroWordNet/). Also, certain resources were given additional specific tasks. For English CWI, in SemEval-2016 [51] a set of instances were presented, each of which had metadata associated with a target word labelled as either simple or complex. Some years later, the same task for English, Spanish, German and French was proposed [43], with the added value of performing classification for uni-words and multi-words. Recently, the ALEXSIS dataset [49] exploited the data from this task to create a new dataset containing simplicity-ranked substitutes for complex words. Also, a recent workshop [48] proposed a resource by challenging the participants to perform the CWI in academic content. Therefore, the proposed systems had to detect which technical words are commonly used in the domain and labelled them as simple words.Most of these resources have been labelled by annotators without knowledge about cognitive accessibility, easy-to-read and plain language guidelines. Also, people with disabilities are not taken into account in the annotation process as is indicated in the “Annotation method” column in Table 1. EASIER corpus addresses this gap providing support for the CWI task and searching the corresponding synonym aimed at people with cognitive impairments, such as the elderly and people with intellectual disabilities, among others. The EASIER corpus has been annotated by easy-to-read and plain language experts following a methodological approach that involves people with disabilities.MethodBefore explaining the methodology, recruitment of annotators, materials and instruments, it is important to mention that the experiments presented in this article have been reviewed to ensure that no confidential information is disclosed and has been approved in written form by an IRB at Universidad Carlos III de Madrid (IRB20_12) on October 28, 2020 and by the participants at subsequent dates.Selection of annotatorsThree annotators have taken part in corpus construction. One annotated the entire corpus (main annotator), while the other two annotated part of the corpus to calculate the Inter-Annotator Agreement (IAA). The three annotators are Spanish native speakers, expert linguists and specialists in easy-to-read and plain language guidelines. They have more than 15 years of experience transforming conventional texts into easy-to-read texts. They belong to Plena Inclusión (https://plenainclusionmadrid.org/) Madrid and Grupo Amas Fácil (https://amasfacil.org/), two organisations that work to offer resources adapted to people with intellectual and learning disabilities. It should be noted that these annotators manually adapted the texts following a methodology that involves people with intellectual disabilities throughout the process.MaterialsTwo hundred and sixty news articles from the “60 y más” magazine (http://www.revista60ymas.es/60mas_01/index.htm), ranging from beginning of 2019 until the first months of 2020, were randomly selected based on their length. News covered a range of different topics in the areas of current affairs, health, guides for seniors and news. Thus, the EASIER corpus is a domain-independent corpus. Each document had a similar length, and the corpus has an average of 15 sentences per document. This journal belongs to Imserso (https://www.imserso.es/imserso_01/index.htm), the Institute for the Elderly and Social Services in Spain. This group’s main objective is to promote the social integration of the elderly through information in Spanish.InstrumentsAnnotators used an annotation tool created as an extension for Google Chrome (https://github.com/ralarcong/EASIER_AnnotationTool). The authors have developed it to (a) select and deselect words that are considered complex or unusual in a given text and (b) propose simple, context-appropriate synonyms for the target word.The corpus construction methodology includes three steps following an iterative process (see Fig 1):Fig 1Corpus building methodology.Annotation Guidelines Definition. Based on the annotator’s experience and knowledge of easy-to-read and plain language guidelines, the main annotator establishes various annotation guidelines to detect complex words and suggest simple synonyms.Annotation Process. The annotator performs the analysis of the texts according to the annotation guidelines using the annotation tool.Annotation Guidelines Validation. In order to validate the annotation guidelines, an initial evaluation with the participation of people with intellectual disabilities of the set of texts annotated to date was performed. Once the documents have been fully annotated, the resulting corpus is described in the “Corpus description” Section. A portion of the data set is extracted and annotated by two other annotators to calculate IAA.The annotation process, which describes the steps of the methodology, is shown below.Annotation guidelines definitionThe main annotator defined the annotations guidelines and annotated complex words in texts accordingly. The terms given below should be annotated as complex terms:Words that are common in verbal communication but probably are unknown to the people under study. The Spanish linguistic frequency indexes (Gran Diccionario de Uso del Español Actual, Corpus CREA (https://corpus.rae.es/lfrecuencias.html), Corpus CORPES XXI (https://www.rae.es/banco-de-datos/corpes-xxi) [4, 6, 52–56] are the resources used to identify these words.The syllable configuration of a word should also be considered. When syllables are long or have more consonants, the effort needed to pronounce them could affect comprehension [6, 54, 56, 57].Long words that are difficult to read and pronounce such as “esternocleidomastoideo”, (sternocleidomastoid), represent difficulty in reading and pronunciation [6, 56].Technical jargon, for example, terms used in the medical or legal fields [4, 6, 55, 56].Abbreviations or acronyms when an explanation is not included in the document. For example, a document explaining the objectives of the WHO, but the expansion “World Health Organization” is not included in the text [4, 6, 55, 56, 58].Words in a language other than the main language of the document. Since EASIER’s target audience is the elderly and people with disabilities, it should not be assumed that they know other languages [4, 6, 56].Roman numerals [6, 56, 59].Idioms because they could have a double meaning that is difficult to understand, such as “cost an arm and a leg” which gives the sense of something expensive [6, 56].Metaphorical expressions because are hard to understand [4, 6, 56].Abstract terms which physical form cannot be perceived or imagined. For example, Terms such as “justice” or “emotion” are considered difficult to understand [4, 6, 56].Multi-word terms of different types [4, 6, 56]:\\nExpressions constructed with complex words. For example, “key indicators” or “contractual resources”.Expressions including simple words whose more familiar meaning has been modified. For example, “social tourism” or “portfolio of services”.Complex expressions including complex and simple words whose most well-known meaning has been modified. For example, “strategic framework” or “inter-territorial council”.Common words whose most frequent meaning is modified by the context in which they are found (linked to polysemy). For example, the “active” word has two senses: (a) the portion of the population either with a job or looking for a job and (b) a person who likes to be active, being the most used the second one [6, 56].Percentages and mathematical expressions, for example, numbers expressing largequantities [4, 6, 56, 60].Adverbs ending in “-mente” (-ly) because of their prolonged pronunciation [6, 56].Collective nouns because are harder to understand than enumeration. For example, the concept “indumentaria” (clothing).Words that are obsolete or in disuse [56].The Table in S1 Table shows examples of selected uni-words or multi-words according to the criteria described in this section are provided.Annotation guidelines validationA quarter of the dataset was annotated to assess the initial set of annotation guidelines, and a set of experiments were carried out with people with cognitive disabilities belonging to the target group. The aim was to evaluate and refine the expert linguist’s annotation guidelines.The participants, the methodology and the results of this validation are explained below.Participants Some validation sessions were held in which people with disabilities are the validators to ensure that the adaptation is being done correctly. Eight people with mild intellectual disabilities (Group 1) and older people (Group 2), with five women and three men were chosen to participate in the initial evaluation. Of the five women, three were people with intellectual disabilities and two were elderly. In the group of men, two were people with intellectual disabilities, and one was an older adult. The validators’ age ranged from 25 to 86, seven with primary education and one with secondary schooling.Methodology The method used to validate easy reading texts by people with intellectual disabilities is supported by results reports from European projects such as the train2validate project (https://plenainclusionmadrid.org/train2validate/?lang=es), Pathways project (https://www.inclusion-europe.eu/pathways-2/), and complies with standards such as Guidance on making written text easy to read and easy to understand [61] and Easy to read. Guidelines and recommendations for elaborating documents [6]. This validation is organized in group sessions with a facilitator, support professional, and people with intellectual disabilities who participated as validator because they have reading comprehension difficulties. The validation session lasted three hours, including a twenty-minute break, and was moderated by a facilitator and our expert in easy-to-read who was annotating our corpus. The validators were provided with documents containing twenty-five complex words. These documents belong to the current affairs section (see Table 2), all framed within sentences and the corresponding synonyms. The moderator projected the document on a screen, then read each sentence aloud and asked the group whether they knew the adverse word or not and its meaning. This was an important step that allowed for assessing the participants’ comprehension capacity and clarifying the concepts if there were doubts. Each validator gave his or her opinion and was free to make comments as they saw fit. The moderator then read the synonyms and reread each sentence aloud, substituting each synonym’s adverse word. Finally, the validators commented on the meaning of each synonym, determined the most appropriate option and, if there were several synonyms, ordered them according to their comprehension criteria, which are as follows:Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Known for both groups: Every validator understands the meaning of the word.Explanation required: Every validator has an idea of the meaning of the word due to its context but at least one of them needs an explanation.Unknown: At least one validator does not know/understand the word.Results and discussion \\nTable 2 shows a portion of the dataset used for evaluation. The human evaluation showed that most of the words represented a challenge for the participants to comprehend (84%), either because they were unfamiliar with said words or needed additional explanation by the moderators. This demonstrates moderate results regarding the quality of the corpus in the decision making of word complexity criteria. For the synonyms proposal, the validators responded well, showing a better understanding of the text with the proposed synonyms. However, users gave a different priority to the suggested synonyms. For example, they understood the word “alteraciones” (alterations) better than the word “irregularidades” (irregularities). Also, users experienced increased difficulty understanding when more than three synonyms were proposed. Thanks to the validation session, the need for several resources or elements to assist in understanding the meaning of a complex word was confirmed. In some cases, it was found that merely showing possible substitutions for a word was not enough for participants to fully understand it, as the user required additional information about the word, such as a definition or an example. This requirement reaffirms the objectives of the EASIER project within which this work is framed. In addition to satisfying the processes of lexical simplification (CWI, SG/SS), this project offers additional comprehension aids such as providing disambiguated definitions and pictograms [10, 62].Corpus descriptionA total of 260 documents were annotated with complex words, from which an average of 15 sentences per document was obtained. As a result, approximately 8,100 complex words were gathered. At the same time, it should be mentioned that more than 5,100 words, for which at least one synonym was proposed, were also obtained (see Table 3).Table 3EASIER corpus statistics.Two distinct datasets could be distinguished: one for Complex Word Identification (CWI) tasks and another for Substitute Generation/Selection (SG/SS) tasks. Each instance of the CWI dataset has six columns (See Table in S2 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the sentence for a particular word.The third column shows the sentence.The fourth and fifth columns show the offset of the target word.The sixth column shows the target word.The seventh column shows the correct label for the binary task (0: simple or 1: complex).For the second dataset, each instance has five columns (See Table in S3 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the target word.The third column shows the target word.The fourth column shows the sentence.The fifth column shows the suggested synonyms for the target word separated commas.EASIER corpus dataset evaluationIn order to determine how well an annotation task is defined, the IAA is used to show how individual annotators compare to each other. This has been done for the CWI adm SG/SS datasets as is explained below.Complex Word Identification (CWI) dataset inter-annotator agreement Two additional annotators performed the agreement. First, for the CWI dataset evaluation, the decision was made to evaluate the Fleiss Kappa coefficient since it is intended for assessments carried out between two or more annotators. However, to obtain a more in-depth analysis between scorers, the Cohen’s Kappa coefficient between each annotator has been evaluated.Following corpus annotation recommendations [63], to evaluate complex words’ annotation, 10% of the corpus was randomly extracted. As a result, 26 documents were obtained, from which 390 sentences to evaluate were obtained. As can be seen in Table 4, these metrics were extracted based on the POS tags, e.g., in the case “N” only metrics were calculated for the nouns of the corpus instances, while for “N—V—A”, they were calculated for the noun, verb and adverb tags as a whole (full evaluation can be found at https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS).Table 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.According to the analysis of results, a moderate result was obtained with a Fleiss Kappa coefficient of 0.641. The highest agreement was reached when analysing the multi-words since long words or phrases make it difficult to understand the message. On the other hand, interjections were considered to have lexical content in some cases. Therefore, these few instances are removed from the corpus.Substitute Generation/Selection (SG/SS) dataset evaluation Inspired by previous work [64–66], a scale-based methodology was used to evaluate the content of the synonym dataset. The original annotator proposed synonyms for a target word and did not assign labels for this dataset. Therefore, to evaluate this dataset and in order to verify the quality of the proposed synonyms, the two additional annotators were asked to assign two types of labels for each synonym: “0: synonym incorrectly defined” and “1: well-defined synonym”. To this end, 10% of the total number of instances were extracted in which the target word needed to have at least three proposed synonyms. As a result, a dataset of 513 target words was obtained together with their respective synonyms.\\nFig 2 shows that positive results were obtained, as evidenced by the clear difference between well-defined and incorrectly defined synonyms. Of the 1,026 synonyms reviewed, annotator 2 rated 987 synonyms as well-defined and 37 as incorrectly defined. In turn, annotator 3 rated 913 synonyms as well-defined and 113 as incorrectly defined. Subsequently, an analysis was carried out of the instances in which the synonyms were rated as incorrectly defined. It was found that in several cases, these words were qualified in this way due to the fact that, although they could fit in the context, they presented some ambiguity with regard to their meaning. An example of this is the word “salubrity” in the sentence “Tiempos en los que la salubridad era escasa.” (Times when salubrity was scarce). The well-defined replacements were “limpieza” (cleanliness) and “hygiene” (hygiene). However, the incorrectly defined replacement was “salud” (health), which may work within the context of the sentence but modifies its semantics.Fig 2Annotations between annotator 2 and 3.User evaluationIn this section, different experiments to validate the EASIER corpus are described including participants, materials, procedure, tasks and metrics used for each experimentation (also available at https://github.com/ralarcong/EASIERCORPUS_EVALUATION).ParticipantsA total of 45 participants were recruited for this experimental study. The inclusion criteria were people with cognitive disabilities that included people with mild cognitive impairments medically identified and older people who have cognitive problems due to age deterioration. In addition, people without disabilities as a control group were considered. The participants were recruited by the HULAT group (https://hulat.inf.uc3m.es/) to which the authors belong in collaboration with the AMAS group (https://www.fundacion-amas.org/), an organization that works to provide resources for people with intellectual disabilities.\\nTable 5 shows an overview of the demographic information of the participants. The participants were divided into three groups: Group 1 represented 15 older people (33.3%), Group 2 represented 15 people with intellectual disabilities (33.3%) and Group 3 represented 15 control users (33.3%).Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).Across the entire population (all groups), the lowest number of participants corresponded to the age group between 34 and 44 years old with 10 participants (22%) and to participants over 71 years old with 7 participants (16%); on the other hand, the highest number of participants corresponded to the age group under 33 years old with 13 participants (29%) and to participants between 45 and 70 years old with 15 participants (33%).There was a small difference between the number of female (53%) and male (47%) people with 24 and 21 participants respectively.Regarding the educational level of the participants, the least number of participants were registered for people with no registered studies and people with a university degree with 3 (7%) and 10 (22%) participants respectively, and the majority had a high school level of education with 20 participants (44%), followed by primary level with 12 participants (27%).Finally, the reading level of the participants was evaluated through the number of books read per year, where the lowest number of participants was concentrated by 1 (2%) participant who read more than 12 books per year, 6 (13%) participants who read 6 to 12 books per year, followed by 9 (20%) participants who read 3 to 6 books per year. While the highest number of participants was presented by participants who do not read any book per year and participants who read 1 to 3 books per year with 15 (32%) and 14 (31%) participants respectively.MaterialsFor this experimental study 29 sentences of similar length were randomly extracted to evaluate the detected complex words and suggested replacements.ProcedureThe ethical committee of the Universidad Carlos III de Madrid (IRB20_12) approved this experimental study for people with and without disabilities on October 28, 2020. Participants were briefed on the purpose of the experiment and signed a consent form. In the case of people with intellectual disabilities, permission was obtained from their legal guardians. Next, participants were asked to complete a simple demographic questionnaire. Finally, each participant was asked to complete the tasks.The validation method used with people with intellectual disabilities was similar to the initial evaluation of the corpus, described in the Annotation Guidelines Validation section. The sessions were conducted at the AMAS Group facilities, where the researcher worked together with the AMAS facilitators. The rest of the tests were carried out at the university facilities, where the researcher worked directly with the user.The main steps were:Demographic questions about age, gender, education level and reading habits.Explanation and performance of task 1, referring to the CWI task.Explanation and performance of task 2, referring to remaining tasks in the lexical simplification process where a substitute is provided by the EASIER corpus.TasksTo evaluate the corpus, the following tasks were defined.Task 1 aims to measure the CWI task, i.e., the annotations of the corpus when discerning between complex and simple words. Each participant had to analyze 14 randomly selected sentences. In each sentence, the participant had to select single or multi-words that he/she judged to be complex or difficult to understand.Task 2 aims to measure the quality of the synonyms of the detected complex words, in order to determine whether the synonyms proposed by the EASIER corpus actually help to improve the cognitive comprehension of the texts. Each participant had to analyze 15 sentences, randomly selected. In each sentence, a detected complex word is highlighted and three candidate synonyms retrieved from the corpus are suggested. Thus, each participant had to analyze the sentences with each candidate and, as a next step, answer yes/no questions about whether the candidate helped to further understand the sentence.MeasuresThe measures in this experimentation were metrics used in the field of machine learning methods in order to compare the proposal with other related works [9, 38], which are the following:Accuracy: Represents the amount of correct identified words among all words.Precision: Amount of positives that are true.Recall: Amount of complex words correctly captured.F-1: The harmonic mean between precision and recallIn addition, different statistical metrics were used to obtain statistical significance, which are described in the next section.Results and discussionThis section gives results and discussions of the experiments described above. Likewise, this section is divided by the type of experimentation, complemented by subsequent analysis.\\nTable 6 shows the scores for task 1. The results were moderate, obtaining an overall F1 score of 0.51 points, with better recall than precision with 0.69 and 0.57 respectively. By evaluating the proposal by groups, a difference in precision was observed between groups 1 (older people), 2 (people with intellectual disabilities) and 3 (control users) with 0.57, 0.59 and 0.55 points, respectively. In turn, regarding the recall, there was a minor difference between groups, with 0.68 points for Group 1, 0.69 points for Group 2 and 0.69 points for Group 3.Table 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\nFig 3 shows a comparison of the precision scores between the study groups, where Group 2 (people with intellectual disabilities) achieved better results than Group 1 (older people) and Group 3 (control users). This indicates that the proposed CWI model achieved a higher number of quality predictions for people with intellectual disabilities than for older people and control users by getting a higher number of true positives. Although the difference in scores between the groups is minimal (about 0.02 points with Group 1 and 0.04 points with Group 3), this suggests that the proposal makes higher quality predictions for people with intellectual disabilities. Statistically comparing the precision between groups, the corpus was shown to be more beneficial for people with intellectual disabilities (Group 2) compared to older people in Group 1 (Wilcoxon test, P = 0.002) and control users in Group 3 (Wilcoxon test, P = 0.03).Fig 3Precision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.On the other hand, when analyzing recall scores, an increase was noted in comparison to precision. Fig 4 compares the recall scores of the study groups, where a greater dispersion of the data is clearly seen in the Group 1 and Group 2 than in the Group 3. This metric is important for this study as the corpus seeks to cover as many terms as possible when providing cognitive language support to people with intellectual disabilities and the elderly. In contrast to precision, the corpus provides greater coverage for older people (Group 1) compared to control users in Group 3 (Wilcoxon test, P = 0.02).Fig 4Recall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.In addition, Fig 5 presents the number of words that each participant considered complex, divided by groups. Most users in groups 1 and 3 are concentrated in the lower part of the graph where they detected a lower number of complex words (between 1 to 10 words across all sentences) and with additional values scattered across the graph. On the other hand, users with intellectual disabilities (Group 2), concentrated in a higher part of the graph by detecting a higher number of complex words, consequently supporting the precision and recall metrics described above.Fig 5Number of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Results achieved in CWI task do not seem very promising. We believe this could be related to ambiguity being greater in the case of open domain texts than in a restricted domain. Most research in NLP is devoted to solve the problem of ambiguity; NLP systems built to understand natural language only perform adequately in the domain for which they are designed and trained [67, 68], because the terminology is narrowed to a topic. Moreover, Gale et al. [69] showed that the sense of a target word is highly consistent within a given document (one meaning per discourse) and this reduces the number of synonyms of words in texts; this is comparable to the reduction of synonyms if texts of a restricted domain are considered. Nevertheless, simplification mechanisms are needed for information websites, such as news sites, that people access in search of information from a wide range of domains, hence the motivation for developing the Easier corpus. Moreover, experimentation with users is extraordinarily complex as it is carried out with subjective questions that measure how complex a word is for each person.Related to the second task, the quality of the synonym dataset was evaluated and, as described above, each participant was asked to evaluate three candidate substitutes for each of the 15 sentences of the study. Table 7 shows three types of results divided by groups, the first where the number of users who accepted at least one of the candidates presented for each sentence is recorded, the second which records the number of users who accepted at least two of the candidates presented for each sentence and the last one being the most rigorous one that counts the number of cases where all candidates were accepted by instance.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.Regarding the first result, an almost perfect percentage of acceptance was achieved for groups 1 (older people) and 2 (people with intellectual disabilities), with an acceptance percentage of 98% and 99% respectively. On the other hand, control users had a lower but close acceptance rate of 95%, mainly because this group of users does not represent the target user of the corpus. Therefore, this implies that the corpus greatly helps to reduce the level of complexity of the sentences, at least with a suggested candidate, and although a good acceptance was achieved in both groups, the group with intellectual disability was the one that received the most benefit. Later, more rigorous tests were carried out, where at least two candidates had to be accepted, obtaining in this case a higher percentage of acceptance of Group 1 than Group 2 with 72% and 69% respectively. Similarly, the acceptance rate of Group 3 dropped to 68%. Finally, when evaluating user responses in scenarios where all candidates were to be accepted, acceptance percentages of 57%, 52% and 32% were obtained for groups 1, 2 and 3, respectively.Concerning the second task, statistical significance tests were performed to understand these results, where it was confirmed that the synonyms provided by the corpus help the population made up of older people in Group 1 and people with intellectual disabilities in Group 2 (Fisher test, P = 0.03), complementing the results shown in Table 7.Later, these results were analyzed in relation to the education and reading level of each population. For example, the results showed statistically that the help of synonyms depended on the reading level of older users (Chi-square, P = 0.01).A similar example is shown in Fig 6 which divides the cases in which at least one substitution was accepted and the cases in which none was accepted, divided by group and educational level. For Group 1 (older people) there is a high number of substitutions accepted in participants with a high school level of education and a high number of acceptance for primary level of education for Group 2 (people with intellectual disabilities). It is worth mentioning that there is a higher concentration of participants with these levels of education for each group. For this same reason, there are cases in which the number of acceptances is low, as in the university level, which only had participants in Group 1.Fig 6Number of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.ConclusionsThis article introduces the EASIER corpus, which compiles a total of 260 Spanish documents of different topics annotated with complex words and synonyms. The EASIER corpus provides support for NLP methods to face lexical simplification in Complex Word Identification (CWI) and Substitute Generation/Selection (SG/SS) tasks. As a result, approximately 8,100 complex words were gathered. Additionally, it contains approximately 5,100 words for which at least one synonym was proposed. This corpus was built thanks to the annotation and evaluation of linguistic experts, who are specialised in easy-to-read and plain language guidelines. Sixteen annotation guidelines to discern between complex and simple words are also defined.The CWI dataset evaluation showed moderate IAA with a Fleiss Kappa coefficient of 0.641. On the other hand, an evaluation of this dataset with both target and control users, achieved a moderate overall F1-score of 0.51 points. However, since this corpus seeks to meet the needs of people with cognitive disabilities, greater importance was given to the recall metric, which was 0.68 and 0.69 points for older people and people with intellectual disabilities, respectively. Finally, a range of significance tests were also performed to confirm the corpus support between populations.Concerning the moderate IAA in complex word annotation tasks, it is important to highlight that tasks that require more interpretation of texts do not obtain a high agreement among annotators [63]. A high IAA is an indicator that the task is well defined and other annotators could replicate the work. Specifying if a word or phrase is a complex term is a subjective task, which influences the IAA value. In addition, the fact that an annotator has a high IAA certainly does not mean that the annotations are correct. It means that annotators have equally interpreted the guidelines. Bayerl and Paul [70] analyzed several factors that could influence IAA through different labeled corpora providing some recommendations to improve IAA like using few categories, recruiting annotators with the same level of domain expertise and providing training to them. To gain confidence in the integrity of annotations, they suggest having larger groups of annotators considering the criticality of tasks. In annotation tasks as the one described in this study, having expert and trained annotators in plain language and easy-to-read guidelines is essential.The evaluation of the SG/SS dataset showed positive results. Out of the 1,026 synonyms analysed, 987 were scored as well-defined by one annotator and 913 by the other one. The same people from the previous study evaluated a portion of the synonym dataset. Near-perfect results were obtained for cases where at least one synonym was accepted (out of 3), and moderate-to-good results were obtained for scenarios where two or more synonyms were accepted. As in the former dataset study, statistical tests were performed in order to confirm various hypotheses.This corpus is publicly available and currently being used in the EASIER platform. It has been created as a resource to assist both researchers and companies in carrying out simplification processes, with the added value that has been validated by people with disabilities.The EASIER corpus provides support for lexical simplification processes in a generic domain; lexical simplification of domain-independent texts is an extremely complex task, hence some of its moderate results. An extension of this resource will be developed for restricted domains (e.g., eGovernment, legal and health texts, among others) in future work. In addition, over the years, different scales have been proposed to evaluate complexity in texts [66], so the incorporation of new complexity scales (non-binary scale) will be evaluated.Supporting informationS1 TableAnnotation criteria examples. (PDF)Click here for additional data file.(1.2M, pdf)S2 TableCWI dataset instance examples. (PDF)Click here for additional data file.(517K, pdf)S3 TableSG/SS dataset instance examples. (PDF)Click here for additional data file.(1.2M, pdf)Funding StatementThis work has been supported by the R&D&i ACCESS2MEET (PID2020-116527RB-I0) project financed by MCIN AEI/10.13039/501100011033/. Additionally, this work is part of the \"Intelligent and interactive home care system for the mitigation of the COVID-19 pandemic\" project (PRTR-REACT UE) awarded by CAM. CONSEJERÍA DE EDUCACIÓN E INVESTIGACIÓN. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.Data AvailabilityEasier corpus available at https://github.com/LURMORENO/EASIER_CORPUS Annotators used an annotation tool created as an extension for Google Chrome: https://github.com/ralarcong/EASIER_AnnotationTool The evaluations carried out on the EASIER corpus can be consulted at: https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS.Article informationPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622PMCID: PMC10096182PMID: 37043424Rodrigo Alarcon, Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Validation, Writing – original draft, Writing – review & editing,#* Lourdes Moreno, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing,# and  Paloma Martínez, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing#Rodrigo Alarcon\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Rodrigo AlarconLourdes Moreno\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Lourdes MorenoPaloma Martínez\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Paloma MartínezNatalia Grabar, Editor\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\n\\nSTL UMR8163 CNRS, FRANCE\\nCorresponding author.#Contributed equally.Competing Interests: The authors have declared that no competing interests exist.* E-mail: se.m3cu.fni@nocralarReceived 2022 Jul 22; Accepted 2023 Mar 13.Copyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Articles from PLOS ONE are provided here courtesy of PLOSReferences1. Eurostat SE. Population projections in the EU; 2020. September. Available from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=People_in_the_EU_-_population_projections&oldid=497115#Population_projections.2. \\nSaggion H. Automatic Text Simplification. vol. 10; 2017. doi: 10.1007/978-3-031-02166-4 [CrossRef] [Google Scholar]3. W3C. Web Content Accesibility Guidelines (WCAG); 2019. Available from: https://www.w3.org/WAI/standards-guidelines/wcag/.4. \\nFreyhoff G, Hess G, Kerr L, Menzel E, Tronbacke B, Van Der Veken K. Make It Simple, European Guidelines for the Production of Easy-to-Read Information for People with Learning Disability for authors, editors, information providers, translators and other interested persons. International League of Societies for Persons with Mental Handicap European Association, Brussels. 1998;. [Google Scholar]5. Smith K, Hallam G, Ghosh SB. Guidelines for professional library/information educational programs-2012. IFLA Education and Training Section, IFLA, The Hague, available at: www.ifla.org/publications/guidelinesfor-professionallibraryinformationeducational-programs-2012 (accessed 25 August 2014). 2012;.6. UNE. Asociación Española de Normalización, UNE 153101:2018 (Easy to read. Guidelines and recommendations for the elaboration of documents); 2018. Available from: https://www.une.org/encuentra-tu-norma/busca-tu-norma/norma?c=N0060036.7. European-Union. How to write clearly; 2011. Available from: https://op.europa.eu/en/publication-detail/-/publication/c2dab20c-0414-408d-87b5-dd3c6e5dd9a5.8. W3C. Grupo de trabajo de accesibilidad para discapacidades cognitivas y de aprendizaje (COGA TF); 2020. Available from: https://www.w3.org/TR/coga-usable/.9. \\nPaetzold GH, Specia L. A survey on lexical simplification. Journal of Artificial Intelligence Research. 2017;60:549–593. doi: 10.1613/jair.5526 [CrossRef] [Google Scholar]10. Moreno L, Alarcon R, Martínez P. EASIER system. Language resources for cognitive accessibility. 22nd International ACM SIGACCESS Conference on Computers and Accessibility (virtual). 2020;.11. \\nAlarcon R, Moreno L, Martínez P. Lexical Simplification System to Improve Web Accessibility. IEEE Access. 2021;9:58755–58767. doi: 10.1109/ACCESS.2021.3072697 [CrossRef] [Google Scholar]12. \\nShardlow M. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications. 2014;4(1):58–70. doi: 10.14569/SpecialIssue.2014.040109 [CrossRef] [Google Scholar]13. \\nAranzabe MJ, De Ilarraza AD, Gonzalez-Dios I. Transforming complex sentences using dependency trees for automatic text simplification in Basque. Procesamiento del lenguaje natural. 2013;50:61–68. [Google Scholar]14. Carroll J, Minnen G, Canning Y, Devlin S, Tait J. Practical simplification of English newspaper text to assist aphasic readers. In: Proceedings of the AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology. Citeseer; 1998. p. 7–10.15. Aluísio S, Gasperin C. Fostering digital inclusion and accessibility: the PorSimples project for simplification of Portuguese texts. In: Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas; 2010. p. 46–53.16. Gala N, Tack A, Javourey-Drevet L, François T, Ziegler JC. Alector: A Parallel Corpus of Simplified French Texts with Alignments of Misreadings by Poor and Dyslexic Readers. In: Proceedings of the Twelfth Language Resources and Evaluation Conference. Marseille, France: European Language Resources Association; 2020. p. 1353–1361. Available from: https://aclanthology.org/2020.lrec-1.169.17. Grabar N, Cardon R. CLEAR—Simple Corpus for Medical French. In: Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA). Tilburg, the Netherlands: Association for Computational Linguistics; 2018. p. 3–9. Available from: https://aclanthology.org/W18-7002.18. Bott S, Saggion H. An unsupervised alignment algorithm for text simplification corpus construction. In: Proceedings of the Workshop on Monolingual Text-To-Text Generation; 2011. p. 20–26.19. \\nSaggion H, Štajner S, Bott S, Mille S, Rello L, Drndarevic B. Making it simplext: Implementation and evaluation of a text simplification system for spanish. ACM Transactions on Accessible Computing (TACCESS). 2015;6(4):1–36. doi: 10.1145/2738046 [CrossRef] [Google Scholar]20. \\nBarbu E, Martín-Valdivia MT, Martínez-Cámara E, Urena-López LA. Language technologies applied to document simplification for helping autistic people. Expert Systems with Applications. 2015;42(12):5076–5086. doi: 10.1016/j.eswa.2015.02.044 [CrossRef] [Google Scholar]21. Saggion H, Ferrés D, Sevens L, Schuurman I, Ripollés M, Rodríguez O. Able to read my mail: An accessible e-mail client with assistive technology. In: Proceedings of the 14th International Web for All Conference; 2017. p. 1–4.22. Alarcon R, Moreno López L, Segura Bedmar I, Martínez Fernández P. Lexical simplification approach using easy-to-read resources. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2019;.23. Alarcon R, Moreno L, Martínez P. Word-Sense disambiguation system for text readability. In: 9th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion; 2020. p. 147–152.24. Baeza-Yates R, Rello L, Dembowski J. Cassa: A context-aware synonym simplification algorithm. In: Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies; 2015. p. 1380–1385.25. \\nAl-Thanyyan SS, Azmi AM. Automated Text Simplification: A Survey. ACM Comput Surv. 2021;54(2). doi: 10.1145/3442695 [CrossRef] [Google Scholar]26. Petersen SE, Ostendorf M. Text simplification for language learners: a corpus analysis. In: Workshop on Speech and Language Technology in Education. Citeseer; 2007.27. Pellow D, Eskenazi M. An open corpus of everyday documents for simplification tasks. In: Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR); 2014. p. 84–93.28. \\nXu W, Callison-Burch C, Napoles C. Problems in current text simplification research: New data can help. Transactions of the Association for Computational Linguistics. 2015;3:283–297. doi: 10.1162/tacl_a_00139 [CrossRef] [Google Scholar]29. \\nCaseli HM, Pereira TF, Specia L, Pardo TA, Gasperin C, Aluísio SM. Building a Brazilian Portuguese parallel corpus of original and simplified texts. Advances in Computational Linguistics, Research in Computer Science. 2009;41:59–70. [Google Scholar]30. Klaper D, Ebling S, Volk M. Building a German/simple German parallel corpus for automatic text simplification. Zurich Open Repository and Archive. 2013;.31. Brunato D, Dell’Orletta F, Venturi G, Montemagni S. Design and annotation of the first Italian corpus for text simplification. In: Proceedings of The 9th Linguistic Annotation Workshop; 2015. p. 31–41.32. Štajner S. New data-driven approaches to text simplification; 2016.33. \\nBrunato D, Dell’Orletta F, Venturi G. Linguistically-Based Comparison of Different Approaches to Building Corpora for Text Simplification: A Case Study on Italian. Frontiers in Psychology. 2022;13. doi: 10.3389/fpsyg.2022.707630\\n [PMC free article] [PubMed] [CrossRef] [Google Scholar]34. Specia L, Jauhar SK, Mihalcea R. Semeval-2012 task 1: English lexical simplification. In: * SEM 2012: The First Joint Conference on Lexical and Computational Semantics–Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012); 2012. p. 347–355.35. \\nSharoff S. Open-source corpora: Using the net to fish for linguistic data. International journal of corpus linguistics. 2006;11(4):435–462. doi: 10.1075/ijcl.11.4.05sha [CrossRef] [Google Scholar]36. De Belder J, Moens MF. A dataset for the evaluation of lexical simplification. In: International Conference on Intelligent Text Processing and Computational Linguistics. Springer; 2012. p. 426–437.37. Horn C, Manduca C, Kauchak D. Learning a lexical simplifier using Wikipedia. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers); 2014. p. 458–463.38. Paetzold G, Specia L. Benchmarking Lexical Simplification Systems. In: Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16). Portorŏz, Slovenia: European Language Resources Association (ELRA); 2016. p. 3074 -3080. Available from: https://aclanthology.org/L16-1491.39. Paetzold G, Specia L. Unsupervised lexical simplification for non-native speakers. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 30; 2016.40. Kauchak D. Improving text simplification language modeling using unsimplified text data. In: Proceedings of the 51st annual meeting of the association for computational linguistics (volume 1: Long papers); 2013. p. 1537–1546.41. Zhu Z, Bernhard D, Gurevych I. A monolingual tree-based translation model for sentence simplification. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010); 2010. p. 1353–1361.42. Kajiwara T, Komachi M. Building a monolingual parallel corpus for text simplification using sentence similarity based on alignment between word embeddings. In: Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers; 2016. p. 1147–1158.43. Yimam SM, Štajner S, Riedl M, Biemann C. Multilingual and cross-lingual complex word identification. In: Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017; 2017. p. 813–822.44. Zhang X, Lapata M. Sentence simplification with deep reinforcement learning. arXiv preprint arXiv:170310931. 2017;.45. Woodsend K, Lapata M. Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming. In: Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. Edinburgh, Scotland, UK.: Association for Computational Linguistics; 2011. p. 409–420. Available from: https://aclanthology.org/D11-1038.46. \\nŠtajner S, Saggion H, Ponzetto SP. Improving lexical coverage of text simplification systems for Spanish. Expert Systems with Applications. 2019;118:80–91. doi: 10.1016/j.eswa.2018.08.034 [CrossRef] [Google Scholar]47. Alva-Manchego F, Martin L, Bordes A, Scarton C, Sagot B, Specia L. ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. arXiv preprint arXiv:200500481. 2020;.48. Ortiz-Zambranoa JA, Montejo-Ráezb A. Overview of ALexS 2020: First Workshop on Lexical Analysis at SEPLN. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2020;.49. Ferrés D, Saggion H. ALEXSIS: A Dataset for Lexical Simplification in Spanish; 2022. [PMC free article] [PubMed]50. \\nMcCarthy D, Navigli R. The English lexical substitution task. Language resources and evaluation. 2009;43(2):139–159. doi: 10.1007/s10579-009-9084-1 [CrossRef] [Google Scholar]51. Paetzold G, Specia L. Semeval 2016 task 11: Complex word identification. In: Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016); 2016. p. 560–569.52. \\nAnula A. Lecturas adaptadas a la enseñanza del español como L2: variables lingüísticas para la determinación del nivel de legibilidad. La evaluación en el aprendizaje y la enseñanza del español como LE L. 2008;2:162–170. [Google Scholar]53. Gunning R, et al. Technique of clear writing. 1952;.54. \\nKincaid J, Fishburn R, Rogers R, Chissom B. Derivation of new readability formulas for Navy enlisted personnel (Research Branch Report 8-75). Memphis, TN: Naval Air Station, Millington, Tennessee. 1975;40. [Google Scholar]55. W3C. WCAG 2.1; 2018. Available from: https://www.w3.org/TR/WCAG21/.56. Muñoz ÓG. Lectura fácil: métodos de redacción y evaluación. Real patronato sobre discapacidad; 2012.57. \\nDrndarevic B, Saggion H. Reducing text complexity through automatic lexical simplification: an empirical study for Spanish. Procesamiento del lenguaje natural. 2012;49:13–20. [Google Scholar]58. \\nAldridge MD. Writing and designing readable patient education materials. Nephrology Nursing Journal. 2004;31(4):373–377.  [PubMed] [Google Scholar]59. \\nBaker SJ. Who can read consumer product information?\\nThe Australian Journal of Hospital Pharmacy. 1997;27(2):126–131. doi: 10.1002/jppr1997272126 [CrossRef] [Google Scholar]60. \\nBautista S, Saggion H. Can Numerical Expressions Be Simpler?\\nImplementation and Demostration of a Numerical Simplification System for Spanish. In: LREC; 2014. p. 956–962. [Google Scholar]61. ISO/IEC. ISO/IEC DIS 23859-1 Information technology — User interfaces — Part 1: Guidance on making written text easy to read and easy to understand; 2022.62. Moreno L, Alarcon R, Martínez P. Designing and Evaluating a User Interface for People with Cognitive Disabilities. In: Proceedings of the XXI International Conference on Human Computer Interaction; 2021. p. 1–8.63. \\nPustejovsky J, Stubbs A. Natural Language Annotation for Machine Learning: A guide to corpus-building for applications. “O’Reilly Media, Inc.”; 2012. [Google Scholar]64. Yu CH, Miller RC. Enhancing web page readability for non-native readers. In: Proceedings of the sIGCHI conference on human factors in computing systems; 2010. p. 2523–2532.65. Alonzo O, Seita M, Glasser A, Huenerfauth M. Automatic text simplification tools for deaf and hard of hearing adults: Benefits of lexical simplification and providing users with autonomy. In: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems; 2020. p. 1–13.66. Shardlow M, Cooper M, Zampieri M. CompLex — A New Corpus for Lexical Complexity Prediction from Likert Scale Data. In: Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI). Marseille, France: European Language Resources Association; 2020. p. 57–62. Available from: https://aclanthology.org/2020.readi-1.9.67. \\nCambria E, White B. Jumping NLP Curves: A Review of Natural Language Processing Research. IEEE Computational Intelligence Magazine. 2014;9(2):48–57. doi: 10.1109/MCI.2014.2307227 [CrossRef] [Google Scholar]68. \\nHirschberg J, Manning CD. Advances in natural language processing. Science. 2015;349(6245):261–266. doi: 10.1126/science.aaa8685\\n [PubMed] [CrossRef] [Google Scholar]69. \\nGale WA, Church K, Yarowsky D. One sense per discourse. In: Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February; \\n23–26, 1992; 1992. [Google Scholar]70. \\nBayerl PS, Paul KI. What determines inter-coder agreement in manual annotations? A meta-analytic investigation. Computational Linguistics. 2011;37(4):699–725. doi: 10.1162/COLI_a_00074 [CrossRef] [Google Scholar]Table 1Text simplification resources for English/Spanish.ResourceAnnotated textSizeLanguage: English (EN) Spanish (ES)Annotation methodSimple English WikipediaA simplified version of regular Wikipedia183,000 content pages to dateENPages edited by 1,203 active usersSemEval 2012 [34]English Internet Corpus [35]2,010 instances of simplicity rankingsENNative English speakersLSeval [36]English Internet Corpus [35]430 instances of simplicity rankingsEN46 Amazon Mechanical Turk (turkers), 9 PHD studentsLexMTurk [37]Wikipedia500 instances with target complex words and simpler synonymsEN50 Turkish English speakingBenchLS [38]Compilation of LSeval and LexMTurk929 instances with an average of 7 candidates per complex wordENCorrected and filtered by English speakersNNSeval [39]Filtered version of BenchLS239 instancesENNon-native english speakersWikipedia—Simple WikipediaSimple English Wikipedia167,689 aligned sentencesENLanguage modelling [40]PWKP (WikiSmall) [41]Wikipedia and Simple Wikipedia108,016 aligned sentencesENStatistical machine translationSimplext [19]News texts200 aligned news textsESHuman editors trained in easy-to-read guidelinesSS Corpus [42]Wikipedia and Simple Wikipedia492,993 aligned sentencesENUnsupervised methodNewsela [28]News articlesParallel simple-complex articles with 11-grade levelsEN, ESManually produced by professional editorsRANLP 2017 [43]Wikipedia14,280 instances with target complex wordsEN, ES54 turkers (Native and non-native speakers)WikiLarge [44]WikiSmall, Aligned sentences pairs [40, 45]2,000 for dev, 359 for test, 296,402 for trainingENCombination of previously created simplification corporaPPDB-S/M [46]PPDB5,709 unigrams for S size, 15,524 unigrams for M sizeESBuilt by filtering and ordering paraphrases pairs from the paraphrases database (PPDB)CASSA [46]CASSA dataset5,640,694 5-gramsESGenerated by extracting all unique 5-grams pairs from CASSA resourceASSET [47]TurkCorpus extension23,590 human simplifications associated with 2,359 sentences from TurkCorpusENAmazon Mechanical TurkVYTEDU-CW) [48]Transcripts of academic videos9,175 words, 723 annotated as complexES430 annotators studentsALEXSIS [49]RANLP 2017 datasets381 instances with an average of 10.28 substitutes per instanceESprolific.co annotatorsOpen in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 1Open in a separate windowCorpus building methodology.Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Target WordSynonymsConclusionEtiquetado (Labelling)Letrero (sign), inscripción (inscription), rótulo (banner)Explanation required for both groupsEtiqueta (formal/label)Ceremonia (ceremony), protocolo (protocol)Explanation required for Group 1Known Group 2Envasados (packaged)Empaquetados (packaging)Known by both groupsA granel (in bulk)Suelto (loose), sin envase (without packaging)Known for both groupsOn-line (Online)en línea (online), conectado a Internet (connected to the Internet)Known by Group 1Explanation required for Group 2Comensales (diners)Invitados (guests)Unknown by Group 1Known by Group 1Saludables (salubrious)Sanos (healthy), beneficiosos (beneficial)Explanation required for both groupsCopiosa (copious)Abundante (abundant)Unknown by both groupsCrudos (raw)sin cocinar (not cooked)Known by both groupsDenominación (denomination)Nombre (name)Explanation required for both groupsReclamar (claim)Demandar (sue), quejarse (complain), exigir (demand)Explanation required for both groupsIrregularidades (irregularities)Anomalía (anomaly), alteración (alteration), variación (variation)Unknown by both groupsÓptimas (optimum)Buenas (good), excelentes (excellent)Explanation required by both groupsEmbalaje (packaging)Envase (container), envoltorio (wrapping)Known for both groupsÍntegro (exhaustive)Entero (whole), completo (complete), intacto (intact)Known for both groupsConsumidor (consumer)Comprador (buyer/purchaser), cliente (client), usuario (user)Explanation required for Group 1Known Group 2Provisional (provisional)Temporales (temporary)Unknown for both groupsConsejo (Council)Asambleas (assembly), juntas (board), comisiones (commission/committee)Known for both groupsProporcionar (provide)Dar (give), proporcionar (provide)Known for both groupsCiudadanía (citizens)Sociedad (society), población (populace), nacionalidad (nationality)Known for both groupsVeraz (veracious)Real (real), cierta (certain), verdadera (true)Unknown by both groupsEficacia (efficiency)Utilidad (usefulness), efectividad (effectiveness)Unknown by both groupsContrastar (contrast)Comprobada (proven), comparada (compared), verificada (verified)Unknown for both groupsSoporte (base)Base (basis), fundamento (foundation), apoyo (support)Unknown for both groupsEvidencias (evidence)Certeza (certainty), seguridad (security), prueba (proof), demostración (demonstration)Known for both groupsOpen in a separate windowTable 3EASIER corpus statistics.EASIERDocuments260Sentences3,778Words134,528Average number of sentences per document15Average number of tokens per document517Total instances for CWI44,975Complex Words8,155Total instances for SG/SS5,130Proposed synonyms7,892Average of complex Words per document30Average of proposed synonyms per document29Complex Words with at least one substitute5,130Open in a separate windowTable 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.POSTAGCohen’s Kappa (Rater 1–2)Cohen’s Kappa (Rater 1–3)Cohen’s Kappa (Rater 2–3)Fleiss Kappa\\nN\\n0.47500.41140.57110.484\\nV\\n0.40820.52180.43850.454\\nA\\n0.20110.19420.46400.31\\nI\\n0.50020.15450.26580.3\\nPN\\n0.22630.24410.53380.347\\nN—V\\n0.46670.43650.55860.487\\nN—V—A\\n0.46280.43740.56020.487\\nN—V—I\\n0.46890.43420.55590.486\\nN—V—I—PN\\n0.43300.42280.55300.471\\nN—V—M\\n0.64550.60790.67280.641\\nN—V—A—M\\n0.64220.60940.67390.641\\nN—V—I—M\\n0.64650.60600.67070.64\\nN—V—I—PN—M\\n0.60670.59260.65970.619Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 2Open in a separate windowAnnotations between annotator 2 and 3.Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).FeaturesGroup 1Group 2Group 3All participantsN = 15%N = 15%N = 15%N = 45%\\nAge\\n71+7(47)----7(16)45–708(53)4(27)3(20)15(33)34–44--5(33)5(33)10(22)33 or younger--6(40)7(47)13(29)\\nGender\\nMale7(47)6(40)8(53)21(47)Female8(53)9(60)7(47)24(53)\\nEducation (Highest completed)\\nNone1(7)2(13)--3(7)Primary school5(33)7(47)--12(27)High school9(60)6(40)5(33)20(44)University education----10(67)10(22)\\nReading experience (books per year)\\nNone3(20)9(60)3(20)15(33)1–35(33)3(20)6(40)14(31)3–64(27)1(7)4(27)9(20)6–123(20)2(13)1(7)6(13)12+----1(7)1(2)Open in a separate windowTable 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\nGROUP 1\\n\\nGROUP 2\\n\\nGROUP 3\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n10.570.780.520.40160.560.520.650.40310.560.520.590.4220.580.780.530.42170.630.590.770.54320.600.550.730.4730.680.740.650.63180.600.550.730.47330.590.550.730.4640.770.800.750.75190.590.550.690.47340.590.540.710.4450.700.740.680.67200.610.570.700.51350.590.550.730.4660.610.700.570.51210.590.560.580.53360.560.510.780.3770.580.780.530.42220.650.610.700.58370.710.700.720.7080.560.780.510.37230.590.560.600.53380.580.530.780.4290.590.680.540.45240.650.610.770.56390.570.520.680.42100.560.580.510.40250.650.610.750.57400.550.500.530.37110.630.800.580.52260.660.620.780.58410.630.590.700.54120.590.650.540.46270.640.610.690.58420.590.540.790.43130.530.510.510.48280.670.640.750.62430.560.520.650.40140.560.780.510.37290.650.610.770.56440.630.590.770.54150.630.730.590.53300.620.590.650.56450.590.540.710.44\\nGROUP 1 SCORES\\n\\nGROUP 2 SCORES\\n\\nGROUP 3 SCORES\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\nALL0.610.570.680.51ALL0.620.590.690.54ALL0.590.550.690.47\\nOVERALL SCORE\\n\\nACURACCY\\n\\nPRECISION\\n\\nRECALL\\n\\nF1\\n0.610.570.690.51Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 3Open in a separate windowPrecision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 4Open in a separate windowRecall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 5Open in a separate windowNumber of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.At least one candidate ranked as correctAt least two candidates ranked as correctAll candidates ranked as correctSentence-IDGrp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)S1151515111213795S21515148107773S31515141099884S4151515121012878S51415141211108105S61515151111141199S7141514101110872S814151310115782S9151414111011875S1015151513121110105S111514141211131086S121515151211131097S1314151410107984S141515139118954S151514141169953\\nMEAN\\n14.7314.8014.2010.8010.4010.138.67.84.8\\nACCEPTANCE (%)\\n989995726968575232Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 6Open in a separate windowNumber of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a1894c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='\\n\\n\\n\\nEASIER corpus: A lexical simplification resource for people with cognitive impairments\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou possibly have javascript turned off.The functionality is limited to basic scrolling.You may switch to Article in classic view.AltPDFEASIER corpus: A lexical simplification resource for people with cognitive impairmentsPLoS One. 2023; 18(4): e0283622. PrevPage 0 of 0NextPrevNextDoneLinksPMC HomeJournal ListPLoS OneShare on FacebookShare on TwitterFeedbackDoneAlternative formatsArticle in classic viewPDF (870K)CiteDoneArticle navigationDoneSettings & HelpA-A+AUTOHelp with PubReaderSwitch to classic viewAbout PubReader✘Previous PageNext Page✘◀no matches yet▶Making articles easier to read in PMC\\n                We are experimenting with display styles that make it easier to read articles in PMC.\\n                The ePub format uses eBook readers, which have several \"ease of reading\" features\\n                already built in.\\n              \\n                The ePub format is best viewed in the iBooks reader. You may notice problems with\\n                the display of certain parts of an article in other eReaders.\\n              \\n                Generating an ePub file may take a long time, please be patient.\\n              CancelDownload articletWelcome to PubReader!\\n                Click on  above to:\\n              Get help with PubReader, or Switch to the classic article view.OkayEASIER corpus: A lexical simplification resource for people with cognitive impairmentsRodrigo Alarcon, Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Validation, Writing – original draft, Writing – review & editing, Lourdes Moreno, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing, and  Paloma Martínez, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editingAdditional article informationAssociated DataSupplementary MaterialsS1 Table: Annotation criteria examples. (PDF)pone.0283622.s001.pdf (1.2M)GUID:\\xa045329E95-023F-4E53-BFCD-4F892D4EB7CDS2 Table: CWI dataset instance examples. (PDF)pone.0283622.s002.pdf (517K)GUID:\\xa08E16D29A-286C-424A-A70F-9DFEAC2BE26FS3 Table: SG/SS dataset instance examples. (PDF)pone.0283622.s003.pdf (1.2M)GUID:\\xa0097CC84D-6046-4C01-8245-40474EC3B25AData Availability StatementEasier corpus available at https://github.com/LURMORENO/EASIER_CORPUS Annotators used an annotation tool created as an extension for Google Chrome: https://github.com/ralarcong/EASIER_AnnotationTool The evaluations carried out on the EASIER corpus can be consulted at: https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS.AbstractThanks to technologies such as the Internet and devices now available to people, we have increasingly greater access to larger quantities of information. However, people with ageing disabilities or intellectual disabilities, non-native speakers, and others have difficulties reading and understanding information. For this reason, it is essential to provide text simplification mechanisms when accessing information. Natural Language Processing methods can be applied to simplify textual content and improve understanding. These methods often use machine learning algorithms and models which require resources, such as corpora, to be trained and tested. This article presents the EASIER corpus, a resource that can be used to build lexical simplification methods to process Spanish domain-independent texts. The EASIER corpus is composed of 260 annotated documents with 8,155 words labelled as complex and 5,130 words with at least one proposed context-aware synonym associated. Expert linguists in easy-to-read and plain language guidelines have annotated the corpus based on their experience adapting texts for people with intellectual disabilities. Sixteen annotation guidelines that discriminate between complex and simple words have been defined to help other groups of experts to generate new annotations. Additionally, an inter-annotator agreement test was performed to validate the corpus, obtaining a Fleiss Kappa coefficient of 0.641. Furthermore, a qualitative evaluation was conducted with 45 users (including people with intellectual disabilities, elderly people, and a control audience). Complex word identification tasks achieved moderate results, but the synonyms proposed to replace complex words achieved almost perfect ratings. This resource has been integrated into the EASIER platform, a tool that helps people with cognitive impairments and intellectual disabilities to read and understand texts more easily.IntroductionInformation and communication technologies, especially the Internet, have transformed how we live and communicate. While millions of texts are produced every day, not all of these texts are easy to understand for everyone due to their complexity. Texts that contain unusual and complicated words can cause cognitive accessibility barriers for people with intellectual disabilities. In this sense, one solution can be to offer cognitively accessible interfaces and simplified text content, which benefit not only individuals with intellectual and learning disabilities but also deaf and deaf-blind individuals, the elderly, the illiterate and immigrants whose native language is different, among others. The need for simplified texts is becoming increasingly critical as the number of individuals with disabilities is growing due to the ageing population [1].Manual production of simplified texts is a non-trivial and, at the same time, time consuming task [2]. In this sense, there are methods that systematically produce simplified content. Natural Language Processing (NLP) and artificial intelligence provide methods to simplify texts promoting readability and understandability for people with intellectual disabilities.Some directives provide guidelines on making content more accessible for individuals with intellectual and learning disabilities. In this regard, the most important noteworthy initiatives are the Web Content Accessibility Guidelines (WCAG) [3], the Easy-to-Read guidelines [4–6], the Plain Language guidelines [7] and the document issued by the Cognitive and Learning Disabilities Accessibility Task Force (W3C-COGA TF) [8]. One specific guideline is frequently repeated in all these initiatives: use a simple lexicon. In addition, other guidelines indicate that providing synonyms for complex words is also beneficial. Therefore, providing simplified texts has been found to be helpful for people with intellectual disabilities from a lexical point of view.Lexical simplification is an essential part of text simplification based on machine learning and deep learning methods to replace specific words with simpler ones for a particular audience. Lexical simplification requires a Complex Word Identification (CWI) task to detect words that are considered difficult for a target audience. Once these words are identified, Substitute Generation/Selection (SG/SS) tasks must offer a more straightforward synonym. SG tasks focus on producing substitutes for a target word in all the contexts in which it may appear. On the other hand, SS tasks collect these substitutes and select those that best fit the context in which the target word was found [9].Although these methods have shown promising results, manually annotated data or corpora are required for training purposes. Unfortunately, for Spanish, few annotated texts are available. This lack of resources has become the motivation for this work.In this article, the EASIER corpus is presented (https://github.com/LURMORENO/EASIER_CORPUS). This corpus aims to support CWI and SG/SS tasks, two important processes in text simplification aimed at an audience with intellectual disabilities. This has been achieved through the assistance of an expert linguist in easy-to-read and plain language guidelines. Two additional experts and people with intellectual disabilities have evaluated the resulting corpus to ensure the quality of the data provided.The EASIER corpus has been integrated into the EASIER tool [10, 11] (https://github.com/LURMORENO/easier) (http://easier.hulat.uc3m.es/), that improves the readability and understandability of texts for users with intellectual disabilities.This article is structured as follows. The “Background” Section introduces previous work related to corpora used in simplification tasks. The “Method” Section describes the steps and resources used to develop the corpus as well as the annotation guidelines. The “Corpus Description” Section provides some statistics of the corpus; the “User Evaluation” Section describes the experiments with different types of users. Finally, the “Conclusions” Section presents some conclusions and future work.BackgroundIn 1996, the first automatic text simplification approach [12] performed a superficial analysis of texts to identify verbs and nouns in complex phrases. Syntactic simplification consists in identifying grammatical complexities in sentences and converting them into much simpler ones [13]. The case of lexical simplification, which is the focus of this work, consists of substituting words in a given phrase to make it simpler without modifying its syntactic structure in any way.The PSET project [14] aimed to create a system that performs lexical and syntactic procedures to assist people with aphasia in reading English newspaper texts. In Portuguese, the PorSimples project [15] developed technologies aimed at improving web content for people with low literacy levels by performing lexical/syntactic modifications and, at the same time, developing resources for this language, such as a parallel corpus with simplified sentences. For the French language, works based on parallel corpora such as the Alector corpus [16] have been presented, which focus on alleviating reading difficulties for people with low reading level or people with dyslexia. Additionally, French domain-specific resources have been proposed, such as the CLEAR corpus [17], which contains parallel instances of medical terms with their simplified version, aiming to alleviate the difficulty present in text with specialized content. The Simplext project [18, 19] worked on Spanish texts using a modular system for lexical and syntactic procedures to help people with cognitive disabilities. The FIRST project [20] was focused on developing language technologies to help autistic people, relying on a set of rules, images and dictionary searches for document simplification. Moreover, for people with intellectual disabilities, an accessible web e-mail client that performed text simplification was developed in the Able2Include project [21] to address web text accessibility in the context of e-mail communication. More recently, the authors in the EASIER project developed a web application that provides people with an easier way to improve the readability and comprehension of texts in Spanish. This work has been carried out with the objective of providing relevant data to improve lexical simplification [10, 22, 23].Text simplification has been approached from different perspectives: using rule-based or machine learning systems to identify and improve complex texts [24]. Currently, deep learning systems are being used to generate a simplified version of a given text in a kind of machine translation process, see [25] for a comprehensive state of the art in text simplification. No matter what type of system is being used, it is always necessary to have resources to build, train or adapt text simplification methods. Annotated and simplified corpora are an essential part of these resources in NLP systems development.Parallel corpora, which contain original texts together with their simplified versions, are very valuable resources for training text simplification algorithms, especially in languages with few resources, as is the case of Spanish. There are parallel corpora with aligned texts with a range of complexity levels; Table 1 shows some examples of relevant related resources in text simplification for English and Spanish.Table 1Text simplification resources for English/Spanish.The most common are corpora comprised of a set of original sentences and their simplified versions. The Simplext project provided new resources such, as a parallel corpus comprised of 200 news texts, including their original and simplified versions. Other examples are [26–28] in English, [29] in Portuguese, [30] in German, [31] in Italian and [18, 28, 32] in Spanish. A recent paper [33] presents an overview of parallel corpora for text simplification in different languages, which complements the contents of Table 1.Regarding lexical simplification, specific resources have been made available over the years. In English, SemEval-2012 [34] provided possible substitutes for a target word ranked in ascending order by their complexity, taking the context into consideration or based on the lexical substitution dataset [50], which focused on finding the best set of candidates for the substitution of a target word. Other resources were created using alignment methods. Horn et al. [37] created a collection of 500 sentences, which became a crowd‐sourced lexical substitution resource sampled from English Wikipedia and Simple English Wikipedia alignments. In Spanish, Baeza-Yates et al. [24] automatically created a database from the Spanish Open Thesaurus and the 5-gram Google Books Ngram Corpus. This resource was then extended in the work of Štajner et al. [46] by combining it with other resources such as OpenThesaurus (https://web.archive.org/) and EuroWordnet (https://archive.illc.uva.nl/EuroWordNet/). Also, certain resources were given additional specific tasks. For English CWI, in SemEval-2016 [51] a set of instances were presented, each of which had metadata associated with a target word labelled as either simple or complex. Some years later, the same task for English, Spanish, German and French was proposed [43], with the added value of performing classification for uni-words and multi-words. Recently, the ALEXSIS dataset [49] exploited the data from this task to create a new dataset containing simplicity-ranked substitutes for complex words. Also, a recent workshop [48] proposed a resource by challenging the participants to perform the CWI in academic content. Therefore, the proposed systems had to detect which technical words are commonly used in the domain and labelled them as simple words.Most of these resources have been labelled by annotators without knowledge about cognitive accessibility, easy-to-read and plain language guidelines. Also, people with disabilities are not taken into account in the annotation process as is indicated in the “Annotation method” column in Table 1. EASIER corpus addresses this gap providing support for the CWI task and searching the corresponding synonym aimed at people with cognitive impairments, such as the elderly and people with intellectual disabilities, among others. The EASIER corpus has been annotated by easy-to-read and plain language experts following a methodological approach that involves people with disabilities.MethodBefore explaining the methodology, recruitment of annotators, materials and instruments, it is important to mention that the experiments presented in this article have been reviewed to ensure that no confidential information is disclosed and has been approved in written form by an IRB at Universidad Carlos III de Madrid (IRB20_12) on October 28, 2020 and by the participants at subsequent dates.Selection of annotatorsThree annotators have taken part in corpus construction. One annotated the entire corpus (main annotator), while the other two annotated part of the corpus to calculate the Inter-Annotator Agreement (IAA). The three annotators are Spanish native speakers, expert linguists and specialists in easy-to-read and plain language guidelines. They have more than 15 years of experience transforming conventional texts into easy-to-read texts. They belong to Plena Inclusión (https://plenainclusionmadrid.org/) Madrid and Grupo Amas Fácil (https://amasfacil.org/), two organisations that work to offer resources adapted to people with intellectual and learning disabilities. It should be noted that these annotators manually adapted the texts following a methodology that involves people with intellectual disabilities throughout the process.MaterialsTwo hundred and sixty news articles from the “60 y más” magazine (http://www.revista60ymas.es/60mas_01/index.htm), ranging from beginning of 2019 until the first months of 2020, were randomly selected based on their length. News covered a range of different topics in the areas of current affairs, health, guides for seniors and news. Thus, the EASIER corpus is a domain-independent corpus. Each document had a similar length, and the corpus has an average of 15 sentences per document. This journal belongs to Imserso (https://www.imserso.es/imserso_01/index.htm), the Institute for the Elderly and Social Services in Spain. This group’s main objective is to promote the social integration of the elderly through information in Spanish.InstrumentsAnnotators used an annotation tool created as an extension for Google Chrome (https://github.com/ralarcong/EASIER_AnnotationTool). The authors have developed it to (a) select and deselect words that are considered complex or unusual in a given text and (b) propose simple, context-appropriate synonyms for the target word.The corpus construction methodology includes three steps following an iterative process (see Fig 1):Fig 1Corpus building methodology.Annotation Guidelines Definition. Based on the annotator’s experience and knowledge of easy-to-read and plain language guidelines, the main annotator establishes various annotation guidelines to detect complex words and suggest simple synonyms.Annotation Process. The annotator performs the analysis of the texts according to the annotation guidelines using the annotation tool.Annotation Guidelines Validation. In order to validate the annotation guidelines, an initial evaluation with the participation of people with intellectual disabilities of the set of texts annotated to date was performed. Once the documents have been fully annotated, the resulting corpus is described in the “Corpus description” Section. A portion of the data set is extracted and annotated by two other annotators to calculate IAA.The annotation process, which describes the steps of the methodology, is shown below.Annotation guidelines definitionThe main annotator defined the annotations guidelines and annotated complex words in texts accordingly. The terms given below should be annotated as complex terms:Words that are common in verbal communication but probably are unknown to the people under study. The Spanish linguistic frequency indexes (Gran Diccionario de Uso del Español Actual, Corpus CREA (https://corpus.rae.es/lfrecuencias.html), Corpus CORPES XXI (https://www.rae.es/banco-de-datos/corpes-xxi) [4, 6, 52–56] are the resources used to identify these words.The syllable configuration of a word should also be considered. When syllables are long or have more consonants, the effort needed to pronounce them could affect comprehension [6, 54, 56, 57].Long words that are difficult to read and pronounce such as “esternocleidomastoideo”, (sternocleidomastoid), represent difficulty in reading and pronunciation [6, 56].Technical jargon, for example, terms used in the medical or legal fields [4, 6, 55, 56].Abbreviations or acronyms when an explanation is not included in the document. For example, a document explaining the objectives of the WHO, but the expansion “World Health Organization” is not included in the text [4, 6, 55, 56, 58].Words in a language other than the main language of the document. Since EASIER’s target audience is the elderly and people with disabilities, it should not be assumed that they know other languages [4, 6, 56].Roman numerals [6, 56, 59].Idioms because they could have a double meaning that is difficult to understand, such as “cost an arm and a leg” which gives the sense of something expensive [6, 56].Metaphorical expressions because are hard to understand [4, 6, 56].Abstract terms which physical form cannot be perceived or imagined. For example, Terms such as “justice” or “emotion” are considered difficult to understand [4, 6, 56].Multi-word terms of different types [4, 6, 56]:\\nExpressions constructed with complex words. For example, “key indicators” or “contractual resources”.Expressions including simple words whose more familiar meaning has been modified. For example, “social tourism” or “portfolio of services”.Complex expressions including complex and simple words whose most well-known meaning has been modified. For example, “strategic framework” or “inter-territorial council”.Common words whose most frequent meaning is modified by the context in which they are found (linked to polysemy). For example, the “active” word has two senses: (a) the portion of the population either with a job or looking for a job and (b) a person who likes to be active, being the most used the second one [6, 56].Percentages and mathematical expressions, for example, numbers expressing largequantities [4, 6, 56, 60].Adverbs ending in “-mente” (-ly) because of their prolonged pronunciation [6, 56].Collective nouns because are harder to understand than enumeration. For example, the concept “indumentaria” (clothing).Words that are obsolete or in disuse [56].The Table in S1 Table shows examples of selected uni-words or multi-words according to the criteria described in this section are provided.Annotation guidelines validationA quarter of the dataset was annotated to assess the initial set of annotation guidelines, and a set of experiments were carried out with people with cognitive disabilities belonging to the target group. The aim was to evaluate and refine the expert linguist’s annotation guidelines.The participants, the methodology and the results of this validation are explained below.Participants Some validation sessions were held in which people with disabilities are the validators to ensure that the adaptation is being done correctly. Eight people with mild intellectual disabilities (Group 1) and older people (Group 2), with five women and three men were chosen to participate in the initial evaluation. Of the five women, three were people with intellectual disabilities and two were elderly. In the group of men, two were people with intellectual disabilities, and one was an older adult. The validators’ age ranged from 25 to 86, seven with primary education and one with secondary schooling.Methodology The method used to validate easy reading texts by people with intellectual disabilities is supported by results reports from European projects such as the train2validate project (https://plenainclusionmadrid.org/train2validate/?lang=es), Pathways project (https://www.inclusion-europe.eu/pathways-2/), and complies with standards such as Guidance on making written text easy to read and easy to understand [61] and Easy to read. Guidelines and recommendations for elaborating documents [6]. This validation is organized in group sessions with a facilitator, support professional, and people with intellectual disabilities who participated as validator because they have reading comprehension difficulties. The validation session lasted three hours, including a twenty-minute break, and was moderated by a facilitator and our expert in easy-to-read who was annotating our corpus. The validators were provided with documents containing twenty-five complex words. These documents belong to the current affairs section (see Table 2), all framed within sentences and the corresponding synonyms. The moderator projected the document on a screen, then read each sentence aloud and asked the group whether they knew the adverse word or not and its meaning. This was an important step that allowed for assessing the participants’ comprehension capacity and clarifying the concepts if there were doubts. Each validator gave his or her opinion and was free to make comments as they saw fit. The moderator then read the synonyms and reread each sentence aloud, substituting each synonym’s adverse word. Finally, the validators commented on the meaning of each synonym, determined the most appropriate option and, if there were several synonyms, ordered them according to their comprehension criteria, which are as follows:Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Known for both groups: Every validator understands the meaning of the word.Explanation required: Every validator has an idea of the meaning of the word due to its context but at least one of them needs an explanation.Unknown: At least one validator does not know/understand the word.Results and discussion \\nTable 2 shows a portion of the dataset used for evaluation. The human evaluation showed that most of the words represented a challenge for the participants to comprehend (84%), either because they were unfamiliar with said words or needed additional explanation by the moderators. This demonstrates moderate results regarding the quality of the corpus in the decision making of word complexity criteria. For the synonyms proposal, the validators responded well, showing a better understanding of the text with the proposed synonyms. However, users gave a different priority to the suggested synonyms. For example, they understood the word “alteraciones” (alterations) better than the word “irregularidades” (irregularities). Also, users experienced increased difficulty understanding when more than three synonyms were proposed. Thanks to the validation session, the need for several resources or elements to assist in understanding the meaning of a complex word was confirmed. In some cases, it was found that merely showing possible substitutions for a word was not enough for participants to fully understand it, as the user required additional information about the word, such as a definition or an example. This requirement reaffirms the objectives of the EASIER project within which this work is framed. In addition to satisfying the processes of lexical simplification (CWI, SG/SS), this project offers additional comprehension aids such as providing disambiguated definitions and pictograms [10, 62].Corpus descriptionA total of 260 documents were annotated with complex words, from which an average of 15 sentences per document was obtained. As a result, approximately 8,100 complex words were gathered. At the same time, it should be mentioned that more than 5,100 words, for which at least one synonym was proposed, were also obtained (see Table 3).Table 3EASIER corpus statistics.Two distinct datasets could be distinguished: one for Complex Word Identification (CWI) tasks and another for Substitute Generation/Selection (SG/SS) tasks. Each instance of the CWI dataset has six columns (See Table in S2 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the sentence for a particular word.The third column shows the sentence.The fourth and fifth columns show the offset of the target word.The sixth column shows the target word.The seventh column shows the correct label for the binary task (0: simple or 1: complex).For the second dataset, each instance has five columns (See Table in S3 Table) and are represented as follows:The first column shows the ID of the document.The second column shows the ID of the target word.The third column shows the target word.The fourth column shows the sentence.The fifth column shows the suggested synonyms for the target word separated commas.EASIER corpus dataset evaluationIn order to determine how well an annotation task is defined, the IAA is used to show how individual annotators compare to each other. This has been done for the CWI adm SG/SS datasets as is explained below.Complex Word Identification (CWI) dataset inter-annotator agreement Two additional annotators performed the agreement. First, for the CWI dataset evaluation, the decision was made to evaluate the Fleiss Kappa coefficient since it is intended for assessments carried out between two or more annotators. However, to obtain a more in-depth analysis between scorers, the Cohen’s Kappa coefficient between each annotator has been evaluated.Following corpus annotation recommendations [63], to evaluate complex words’ annotation, 10% of the corpus was randomly extracted. As a result, 26 documents were obtained, from which 390 sentences to evaluate were obtained. As can be seen in Table 4, these metrics were extracted based on the POS tags, e.g., in the case “N” only metrics were calculated for the nouns of the corpus instances, while for “N—V—A”, they were calculated for the noun, verb and adverb tags as a whole (full evaluation can be found at https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS).Table 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.According to the analysis of results, a moderate result was obtained with a Fleiss Kappa coefficient of 0.641. The highest agreement was reached when analysing the multi-words since long words or phrases make it difficult to understand the message. On the other hand, interjections were considered to have lexical content in some cases. Therefore, these few instances are removed from the corpus.Substitute Generation/Selection (SG/SS) dataset evaluation Inspired by previous work [64–66], a scale-based methodology was used to evaluate the content of the synonym dataset. The original annotator proposed synonyms for a target word and did not assign labels for this dataset. Therefore, to evaluate this dataset and in order to verify the quality of the proposed synonyms, the two additional annotators were asked to assign two types of labels for each synonym: “0: synonym incorrectly defined” and “1: well-defined synonym”. To this end, 10% of the total number of instances were extracted in which the target word needed to have at least three proposed synonyms. As a result, a dataset of 513 target words was obtained together with their respective synonyms.\\nFig 2 shows that positive results were obtained, as evidenced by the clear difference between well-defined and incorrectly defined synonyms. Of the 1,026 synonyms reviewed, annotator 2 rated 987 synonyms as well-defined and 37 as incorrectly defined. In turn, annotator 3 rated 913 synonyms as well-defined and 113 as incorrectly defined. Subsequently, an analysis was carried out of the instances in which the synonyms were rated as incorrectly defined. It was found that in several cases, these words were qualified in this way due to the fact that, although they could fit in the context, they presented some ambiguity with regard to their meaning. An example of this is the word “salubrity” in the sentence “Tiempos en los que la salubridad era escasa.” (Times when salubrity was scarce). The well-defined replacements were “limpieza” (cleanliness) and “hygiene” (hygiene). However, the incorrectly defined replacement was “salud” (health), which may work within the context of the sentence but modifies its semantics.Fig 2Annotations between annotator 2 and 3.User evaluationIn this section, different experiments to validate the EASIER corpus are described including participants, materials, procedure, tasks and metrics used for each experimentation (also available at https://github.com/ralarcong/EASIERCORPUS_EVALUATION).ParticipantsA total of 45 participants were recruited for this experimental study. The inclusion criteria were people with cognitive disabilities that included people with mild cognitive impairments medically identified and older people who have cognitive problems due to age deterioration. In addition, people without disabilities as a control group were considered. The participants were recruited by the HULAT group (https://hulat.inf.uc3m.es/) to which the authors belong in collaboration with the AMAS group (https://www.fundacion-amas.org/), an organization that works to provide resources for people with intellectual disabilities.\\nTable 5 shows an overview of the demographic information of the participants. The participants were divided into three groups: Group 1 represented 15 older people (33.3%), Group 2 represented 15 people with intellectual disabilities (33.3%) and Group 3 represented 15 control users (33.3%).Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).Across the entire population (all groups), the lowest number of participants corresponded to the age group between 34 and 44 years old with 10 participants (22%) and to participants over 71 years old with 7 participants (16%); on the other hand, the highest number of participants corresponded to the age group under 33 years old with 13 participants (29%) and to participants between 45 and 70 years old with 15 participants (33%).There was a small difference between the number of female (53%) and male (47%) people with 24 and 21 participants respectively.Regarding the educational level of the participants, the least number of participants were registered for people with no registered studies and people with a university degree with 3 (7%) and 10 (22%) participants respectively, and the majority had a high school level of education with 20 participants (44%), followed by primary level with 12 participants (27%).Finally, the reading level of the participants was evaluated through the number of books read per year, where the lowest number of participants was concentrated by 1 (2%) participant who read more than 12 books per year, 6 (13%) participants who read 6 to 12 books per year, followed by 9 (20%) participants who read 3 to 6 books per year. While the highest number of participants was presented by participants who do not read any book per year and participants who read 1 to 3 books per year with 15 (32%) and 14 (31%) participants respectively.MaterialsFor this experimental study 29 sentences of similar length were randomly extracted to evaluate the detected complex words and suggested replacements.ProcedureThe ethical committee of the Universidad Carlos III de Madrid (IRB20_12) approved this experimental study for people with and without disabilities on October 28, 2020. Participants were briefed on the purpose of the experiment and signed a consent form. In the case of people with intellectual disabilities, permission was obtained from their legal guardians. Next, participants were asked to complete a simple demographic questionnaire. Finally, each participant was asked to complete the tasks.The validation method used with people with intellectual disabilities was similar to the initial evaluation of the corpus, described in the Annotation Guidelines Validation section. The sessions were conducted at the AMAS Group facilities, where the researcher worked together with the AMAS facilitators. The rest of the tests were carried out at the university facilities, where the researcher worked directly with the user.The main steps were:Demographic questions about age, gender, education level and reading habits.Explanation and performance of task 1, referring to the CWI task.Explanation and performance of task 2, referring to remaining tasks in the lexical simplification process where a substitute is provided by the EASIER corpus.TasksTo evaluate the corpus, the following tasks were defined.Task 1 aims to measure the CWI task, i.e., the annotations of the corpus when discerning between complex and simple words. Each participant had to analyze 14 randomly selected sentences. In each sentence, the participant had to select single or multi-words that he/she judged to be complex or difficult to understand.Task 2 aims to measure the quality of the synonyms of the detected complex words, in order to determine whether the synonyms proposed by the EASIER corpus actually help to improve the cognitive comprehension of the texts. Each participant had to analyze 15 sentences, randomly selected. In each sentence, a detected complex word is highlighted and three candidate synonyms retrieved from the corpus are suggested. Thus, each participant had to analyze the sentences with each candidate and, as a next step, answer yes/no questions about whether the candidate helped to further understand the sentence.MeasuresThe measures in this experimentation were metrics used in the field of machine learning methods in order to compare the proposal with other related works [9, 38], which are the following:Accuracy: Represents the amount of correct identified words among all words.Precision: Amount of positives that are true.Recall: Amount of complex words correctly captured.F-1: The harmonic mean between precision and recallIn addition, different statistical metrics were used to obtain statistical significance, which are described in the next section.Results and discussionThis section gives results and discussions of the experiments described above. Likewise, this section is divided by the type of experimentation, complemented by subsequent analysis.\\nTable 6 shows the scores for task 1. The results were moderate, obtaining an overall F1 score of 0.51 points, with better recall than precision with 0.69 and 0.57 respectively. By evaluating the proposal by groups, a difference in precision was observed between groups 1 (older people), 2 (people with intellectual disabilities) and 3 (control users) with 0.57, 0.59 and 0.55 points, respectively. In turn, regarding the recall, there was a minor difference between groups, with 0.68 points for Group 1, 0.69 points for Group 2 and 0.69 points for Group 3.Table 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\nFig 3 shows a comparison of the precision scores between the study groups, where Group 2 (people with intellectual disabilities) achieved better results than Group 1 (older people) and Group 3 (control users). This indicates that the proposed CWI model achieved a higher number of quality predictions for people with intellectual disabilities than for older people and control users by getting a higher number of true positives. Although the difference in scores between the groups is minimal (about 0.02 points with Group 1 and 0.04 points with Group 3), this suggests that the proposal makes higher quality predictions for people with intellectual disabilities. Statistically comparing the precision between groups, the corpus was shown to be more beneficial for people with intellectual disabilities (Group 2) compared to older people in Group 1 (Wilcoxon test, P = 0.002) and control users in Group 3 (Wilcoxon test, P = 0.03).Fig 3Precision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.On the other hand, when analyzing recall scores, an increase was noted in comparison to precision. Fig 4 compares the recall scores of the study groups, where a greater dispersion of the data is clearly seen in the Group 1 and Group 2 than in the Group 3. This metric is important for this study as the corpus seeks to cover as many terms as possible when providing cognitive language support to people with intellectual disabilities and the elderly. In contrast to precision, the corpus provides greater coverage for older people (Group 1) compared to control users in Group 3 (Wilcoxon test, P = 0.02).Fig 4Recall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.In addition, Fig 5 presents the number of words that each participant considered complex, divided by groups. Most users in groups 1 and 3 are concentrated in the lower part of the graph where they detected a lower number of complex words (between 1 to 10 words across all sentences) and with additional values scattered across the graph. On the other hand, users with intellectual disabilities (Group 2), concentrated in a higher part of the graph by detecting a higher number of complex words, consequently supporting the precision and recall metrics described above.Fig 5Number of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Results achieved in CWI task do not seem very promising. We believe this could be related to ambiguity being greater in the case of open domain texts than in a restricted domain. Most research in NLP is devoted to solve the problem of ambiguity; NLP systems built to understand natural language only perform adequately in the domain for which they are designed and trained [67, 68], because the terminology is narrowed to a topic. Moreover, Gale et al. [69] showed that the sense of a target word is highly consistent within a given document (one meaning per discourse) and this reduces the number of synonyms of words in texts; this is comparable to the reduction of synonyms if texts of a restricted domain are considered. Nevertheless, simplification mechanisms are needed for information websites, such as news sites, that people access in search of information from a wide range of domains, hence the motivation for developing the Easier corpus. Moreover, experimentation with users is extraordinarily complex as it is carried out with subjective questions that measure how complex a word is for each person.Related to the second task, the quality of the synonym dataset was evaluated and, as described above, each participant was asked to evaluate three candidate substitutes for each of the 15 sentences of the study. Table 7 shows three types of results divided by groups, the first where the number of users who accepted at least one of the candidates presented for each sentence is recorded, the second which records the number of users who accepted at least two of the candidates presented for each sentence and the last one being the most rigorous one that counts the number of cases where all candidates were accepted by instance.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.Regarding the first result, an almost perfect percentage of acceptance was achieved for groups 1 (older people) and 2 (people with intellectual disabilities), with an acceptance percentage of 98% and 99% respectively. On the other hand, control users had a lower but close acceptance rate of 95%, mainly because this group of users does not represent the target user of the corpus. Therefore, this implies that the corpus greatly helps to reduce the level of complexity of the sentences, at least with a suggested candidate, and although a good acceptance was achieved in both groups, the group with intellectual disability was the one that received the most benefit. Later, more rigorous tests were carried out, where at least two candidates had to be accepted, obtaining in this case a higher percentage of acceptance of Group 1 than Group 2 with 72% and 69% respectively. Similarly, the acceptance rate of Group 3 dropped to 68%. Finally, when evaluating user responses in scenarios where all candidates were to be accepted, acceptance percentages of 57%, 52% and 32% were obtained for groups 1, 2 and 3, respectively.Concerning the second task, statistical significance tests were performed to understand these results, where it was confirmed that the synonyms provided by the corpus help the population made up of older people in Group 1 and people with intellectual disabilities in Group 2 (Fisher test, P = 0.03), complementing the results shown in Table 7.Later, these results were analyzed in relation to the education and reading level of each population. For example, the results showed statistically that the help of synonyms depended on the reading level of older users (Chi-square, P = 0.01).A similar example is shown in Fig 6 which divides the cases in which at least one substitution was accepted and the cases in which none was accepted, divided by group and educational level. For Group 1 (older people) there is a high number of substitutions accepted in participants with a high school level of education and a high number of acceptance for primary level of education for Group 2 (people with intellectual disabilities). It is worth mentioning that there is a higher concentration of participants with these levels of education for each group. For this same reason, there are cases in which the number of acceptances is low, as in the university level, which only had participants in Group 1.Fig 6Number of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.ConclusionsThis article introduces the EASIER corpus, which compiles a total of 260 Spanish documents of different topics annotated with complex words and synonyms. The EASIER corpus provides support for NLP methods to face lexical simplification in Complex Word Identification (CWI) and Substitute Generation/Selection (SG/SS) tasks. As a result, approximately 8,100 complex words were gathered. Additionally, it contains approximately 5,100 words for which at least one synonym was proposed. This corpus was built thanks to the annotation and evaluation of linguistic experts, who are specialised in easy-to-read and plain language guidelines. Sixteen annotation guidelines to discern between complex and simple words are also defined.The CWI dataset evaluation showed moderate IAA with a Fleiss Kappa coefficient of 0.641. On the other hand, an evaluation of this dataset with both target and control users, achieved a moderate overall F1-score of 0.51 points. However, since this corpus seeks to meet the needs of people with cognitive disabilities, greater importance was given to the recall metric, which was 0.68 and 0.69 points for older people and people with intellectual disabilities, respectively. Finally, a range of significance tests were also performed to confirm the corpus support between populations.Concerning the moderate IAA in complex word annotation tasks, it is important to highlight that tasks that require more interpretation of texts do not obtain a high agreement among annotators [63]. A high IAA is an indicator that the task is well defined and other annotators could replicate the work. Specifying if a word or phrase is a complex term is a subjective task, which influences the IAA value. In addition, the fact that an annotator has a high IAA certainly does not mean that the annotations are correct. It means that annotators have equally interpreted the guidelines. Bayerl and Paul [70] analyzed several factors that could influence IAA through different labeled corpora providing some recommendations to improve IAA like using few categories, recruiting annotators with the same level of domain expertise and providing training to them. To gain confidence in the integrity of annotations, they suggest having larger groups of annotators considering the criticality of tasks. In annotation tasks as the one described in this study, having expert and trained annotators in plain language and easy-to-read guidelines is essential.The evaluation of the SG/SS dataset showed positive results. Out of the 1,026 synonyms analysed, 987 were scored as well-defined by one annotator and 913 by the other one. The same people from the previous study evaluated a portion of the synonym dataset. Near-perfect results were obtained for cases where at least one synonym was accepted (out of 3), and moderate-to-good results were obtained for scenarios where two or more synonyms were accepted. As in the former dataset study, statistical tests were performed in order to confirm various hypotheses.This corpus is publicly available and currently being used in the EASIER platform. It has been created as a resource to assist both researchers and companies in carrying out simplification processes, with the added value that has been validated by people with disabilities.The EASIER corpus provides support for lexical simplification processes in a generic domain; lexical simplification of domain-independent texts is an extremely complex task, hence some of its moderate results. An extension of this resource will be developed for restricted domains (e.g., eGovernment, legal and health texts, among others) in future work. In addition, over the years, different scales have been proposed to evaluate complexity in texts [66], so the incorporation of new complexity scales (non-binary scale) will be evaluated.Supporting informationS1 TableAnnotation criteria examples. (PDF)Click here for additional data file.(1.2M, pdf)S2 TableCWI dataset instance examples. (PDF)Click here for additional data file.(517K, pdf)S3 TableSG/SS dataset instance examples. (PDF)Click here for additional data file.(1.2M, pdf)Funding StatementThis work has been supported by the R&D&i ACCESS2MEET (PID2020-116527RB-I0) project financed by MCIN AEI/10.13039/501100011033/. Additionally, this work is part of the \"Intelligent and interactive home care system for the mitigation of the COVID-19 pandemic\" project (PRTR-REACT UE) awarded by CAM. CONSEJERÍA DE EDUCACIÓN E INVESTIGACIÓN. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.Data AvailabilityEasier corpus available at https://github.com/LURMORENO/EASIER_CORPUS Annotators used an annotation tool created as an extension for Google Chrome: https://github.com/ralarcong/EASIER_AnnotationTool The evaluations carried out on the EASIER corpus can be consulted at: https://github.com/ralarcong/EASIERCORPUS_EVALUATIONS.Article informationPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622PMCID: PMC10096182PMID: 37043424Rodrigo Alarcon, Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Validation, Writing – original draft, Writing – review & editing,#* Lourdes Moreno, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing,# and  Paloma Martínez, Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Supervision, Validation, Writing – review & editing#Rodrigo Alarcon\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Rodrigo AlarconLourdes Moreno\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Lourdes MorenoPaloma Martínez\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\nFind articles by Paloma MartínezNatalia Grabar, Editor\\nComputer Science and Engineering Department, Universidad Carlos III de Madrid, Madrid, Spain\\n\\nSTL UMR8163 CNRS, FRANCE\\nCorresponding author.#Contributed equally.Competing Interests: The authors have declared that no competing interests exist.* E-mail: se.m3cu.fni@nocralarReceived 2022 Jul 22; Accepted 2023 Mar 13.Copyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Articles from PLOS ONE are provided here courtesy of PLOSReferences1. Eurostat SE. Population projections in the EU; 2020. September. Available from: https://ec.europa.eu/eurostat/statistics-explained/index.php?title=People_in_the_EU_-_population_projections&oldid=497115#Population_projections.2. \\nSaggion H. Automatic Text Simplification. vol. 10; 2017. doi: 10.1007/978-3-031-02166-4 [CrossRef] [Google Scholar]3. W3C. Web Content Accesibility Guidelines (WCAG); 2019. Available from: https://www.w3.org/WAI/standards-guidelines/wcag/.4. \\nFreyhoff G, Hess G, Kerr L, Menzel E, Tronbacke B, Van Der Veken K. Make It Simple, European Guidelines for the Production of Easy-to-Read Information for People with Learning Disability for authors, editors, information providers, translators and other interested persons. International League of Societies for Persons with Mental Handicap European Association, Brussels. 1998;. [Google Scholar]5. Smith K, Hallam G, Ghosh SB. Guidelines for professional library/information educational programs-2012. IFLA Education and Training Section, IFLA, The Hague, available at: www.ifla.org/publications/guidelinesfor-professionallibraryinformationeducational-programs-2012 (accessed 25 August 2014). 2012;.6. UNE. Asociación Española de Normalización, UNE 153101:2018 (Easy to read. Guidelines and recommendations for the elaboration of documents); 2018. Available from: https://www.une.org/encuentra-tu-norma/busca-tu-norma/norma?c=N0060036.7. European-Union. How to write clearly; 2011. Available from: https://op.europa.eu/en/publication-detail/-/publication/c2dab20c-0414-408d-87b5-dd3c6e5dd9a5.8. W3C. Grupo de trabajo de accesibilidad para discapacidades cognitivas y de aprendizaje (COGA TF); 2020. Available from: https://www.w3.org/TR/coga-usable/.9. \\nPaetzold GH, Specia L. A survey on lexical simplification. Journal of Artificial Intelligence Research. 2017;60:549–593. doi: 10.1613/jair.5526 [CrossRef] [Google Scholar]10. Moreno L, Alarcon R, Martínez P. EASIER system. Language resources for cognitive accessibility. 22nd International ACM SIGACCESS Conference on Computers and Accessibility (virtual). 2020;.11. \\nAlarcon R, Moreno L, Martínez P. Lexical Simplification System to Improve Web Accessibility. IEEE Access. 2021;9:58755–58767. doi: 10.1109/ACCESS.2021.3072697 [CrossRef] [Google Scholar]12. \\nShardlow M. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications. 2014;4(1):58–70. doi: 10.14569/SpecialIssue.2014.040109 [CrossRef] [Google Scholar]13. \\nAranzabe MJ, De Ilarraza AD, Gonzalez-Dios I. Transforming complex sentences using dependency trees for automatic text simplification in Basque. Procesamiento del lenguaje natural. 2013;50:61–68. [Google Scholar]14. Carroll J, Minnen G, Canning Y, Devlin S, Tait J. Practical simplification of English newspaper text to assist aphasic readers. In: Proceedings of the AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology. Citeseer; 1998. p. 7–10.15. Aluísio S, Gasperin C. Fostering digital inclusion and accessibility: the PorSimples project for simplification of Portuguese texts. In: Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas; 2010. p. 46–53.16. Gala N, Tack A, Javourey-Drevet L, François T, Ziegler JC. Alector: A Parallel Corpus of Simplified French Texts with Alignments of Misreadings by Poor and Dyslexic Readers. In: Proceedings of the Twelfth Language Resources and Evaluation Conference. Marseille, France: European Language Resources Association; 2020. p. 1353–1361. Available from: https://aclanthology.org/2020.lrec-1.169.17. Grabar N, Cardon R. CLEAR—Simple Corpus for Medical French. In: Proceedings of the 1st Workshop on Automatic Text Adaptation (ATA). Tilburg, the Netherlands: Association for Computational Linguistics; 2018. p. 3–9. Available from: https://aclanthology.org/W18-7002.18. Bott S, Saggion H. An unsupervised alignment algorithm for text simplification corpus construction. In: Proceedings of the Workshop on Monolingual Text-To-Text Generation; 2011. p. 20–26.19. \\nSaggion H, Štajner S, Bott S, Mille S, Rello L, Drndarevic B. Making it simplext: Implementation and evaluation of a text simplification system for spanish. ACM Transactions on Accessible Computing (TACCESS). 2015;6(4):1–36. doi: 10.1145/2738046 [CrossRef] [Google Scholar]20. \\nBarbu E, Martín-Valdivia MT, Martínez-Cámara E, Urena-López LA. Language technologies applied to document simplification for helping autistic people. Expert Systems with Applications. 2015;42(12):5076–5086. doi: 10.1016/j.eswa.2015.02.044 [CrossRef] [Google Scholar]21. Saggion H, Ferrés D, Sevens L, Schuurman I, Ripollés M, Rodríguez O. Able to read my mail: An accessible e-mail client with assistive technology. In: Proceedings of the 14th International Web for All Conference; 2017. p. 1–4.22. Alarcon R, Moreno López L, Segura Bedmar I, Martínez Fernández P. Lexical simplification approach using easy-to-read resources. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2019;.23. Alarcon R, Moreno L, Martínez P. Word-Sense disambiguation system for text readability. In: 9th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-exclusion; 2020. p. 147–152.24. Baeza-Yates R, Rello L, Dembowski J. Cassa: A context-aware synonym simplification algorithm. In: Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies; 2015. p. 1380–1385.25. \\nAl-Thanyyan SS, Azmi AM. Automated Text Simplification: A Survey. ACM Comput Surv. 2021;54(2). doi: 10.1145/3442695 [CrossRef] [Google Scholar]26. Petersen SE, Ostendorf M. Text simplification for language learners: a corpus analysis. In: Workshop on Speech and Language Technology in Education. Citeseer; 2007.27. Pellow D, Eskenazi M. An open corpus of everyday documents for simplification tasks. In: Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR); 2014. p. 84–93.28. \\nXu W, Callison-Burch C, Napoles C. Problems in current text simplification research: New data can help. Transactions of the Association for Computational Linguistics. 2015;3:283–297. doi: 10.1162/tacl_a_00139 [CrossRef] [Google Scholar]29. \\nCaseli HM, Pereira TF, Specia L, Pardo TA, Gasperin C, Aluísio SM. Building a Brazilian Portuguese parallel corpus of original and simplified texts. Advances in Computational Linguistics, Research in Computer Science. 2009;41:59–70. [Google Scholar]30. Klaper D, Ebling S, Volk M. Building a German/simple German parallel corpus for automatic text simplification. Zurich Open Repository and Archive. 2013;.31. Brunato D, Dell’Orletta F, Venturi G, Montemagni S. Design and annotation of the first Italian corpus for text simplification. In: Proceedings of The 9th Linguistic Annotation Workshop; 2015. p. 31–41.32. Štajner S. New data-driven approaches to text simplification; 2016.33. \\nBrunato D, Dell’Orletta F, Venturi G. Linguistically-Based Comparison of Different Approaches to Building Corpora for Text Simplification: A Case Study on Italian. Frontiers in Psychology. 2022;13. doi: 10.3389/fpsyg.2022.707630\\n [PMC free article] [PubMed] [CrossRef] [Google Scholar]34. Specia L, Jauhar SK, Mihalcea R. Semeval-2012 task 1: English lexical simplification. In: * SEM 2012: The First Joint Conference on Lexical and Computational Semantics–Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012); 2012. p. 347–355.35. \\nSharoff S. Open-source corpora: Using the net to fish for linguistic data. International journal of corpus linguistics. 2006;11(4):435–462. doi: 10.1075/ijcl.11.4.05sha [CrossRef] [Google Scholar]36. De Belder J, Moens MF. A dataset for the evaluation of lexical simplification. In: International Conference on Intelligent Text Processing and Computational Linguistics. Springer; 2012. p. 426–437.37. Horn C, Manduca C, Kauchak D. Learning a lexical simplifier using Wikipedia. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers); 2014. p. 458–463.38. Paetzold G, Specia L. Benchmarking Lexical Simplification Systems. In: Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16). Portorŏz, Slovenia: European Language Resources Association (ELRA); 2016. p. 3074 -3080. Available from: https://aclanthology.org/L16-1491.39. Paetzold G, Specia L. Unsupervised lexical simplification for non-native speakers. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol. 30; 2016.40. Kauchak D. Improving text simplification language modeling using unsimplified text data. In: Proceedings of the 51st annual meeting of the association for computational linguistics (volume 1: Long papers); 2013. p. 1537–1546.41. Zhu Z, Bernhard D, Gurevych I. A monolingual tree-based translation model for sentence simplification. In: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010); 2010. p. 1353–1361.42. Kajiwara T, Komachi M. Building a monolingual parallel corpus for text simplification using sentence similarity based on alignment between word embeddings. In: Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers; 2016. p. 1147–1158.43. Yimam SM, Štajner S, Riedl M, Biemann C. Multilingual and cross-lingual complex word identification. In: Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017; 2017. p. 813–822.44. Zhang X, Lapata M. Sentence simplification with deep reinforcement learning. arXiv preprint arXiv:170310931. 2017;.45. Woodsend K, Lapata M. Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming. In: Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. Edinburgh, Scotland, UK.: Association for Computational Linguistics; 2011. p. 409–420. Available from: https://aclanthology.org/D11-1038.46. \\nŠtajner S, Saggion H, Ponzetto SP. Improving lexical coverage of text simplification systems for Spanish. Expert Systems with Applications. 2019;118:80–91. doi: 10.1016/j.eswa.2018.08.034 [CrossRef] [Google Scholar]47. Alva-Manchego F, Martin L, Bordes A, Scarton C, Sagot B, Specia L. ASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. arXiv preprint arXiv:200500481. 2020;.48. Ortiz-Zambranoa JA, Montejo-Ráezb A. Overview of ALexS 2020: First Workshop on Lexical Analysis at SEPLN. Sociedad Española para el Procesamiento del Lenguaje Natural (SEPLN). 2020;.49. Ferrés D, Saggion H. ALEXSIS: A Dataset for Lexical Simplification in Spanish; 2022. [PMC free article] [PubMed]50. \\nMcCarthy D, Navigli R. The English lexical substitution task. Language resources and evaluation. 2009;43(2):139–159. doi: 10.1007/s10579-009-9084-1 [CrossRef] [Google Scholar]51. Paetzold G, Specia L. Semeval 2016 task 11: Complex word identification. In: Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016); 2016. p. 560–569.52. \\nAnula A. Lecturas adaptadas a la enseñanza del español como L2: variables lingüísticas para la determinación del nivel de legibilidad. La evaluación en el aprendizaje y la enseñanza del español como LE L. 2008;2:162–170. [Google Scholar]53. Gunning R, et al. Technique of clear writing. 1952;.54. \\nKincaid J, Fishburn R, Rogers R, Chissom B. Derivation of new readability formulas for Navy enlisted personnel (Research Branch Report 8-75). Memphis, TN: Naval Air Station, Millington, Tennessee. 1975;40. [Google Scholar]55. W3C. WCAG 2.1; 2018. Available from: https://www.w3.org/TR/WCAG21/.56. Muñoz ÓG. Lectura fácil: métodos de redacción y evaluación. Real patronato sobre discapacidad; 2012.57. \\nDrndarevic B, Saggion H. Reducing text complexity through automatic lexical simplification: an empirical study for Spanish. Procesamiento del lenguaje natural. 2012;49:13–20. [Google Scholar]58. \\nAldridge MD. Writing and designing readable patient education materials. Nephrology Nursing Journal. 2004;31(4):373–377.  [PubMed] [Google Scholar]59. \\nBaker SJ. Who can read consumer product information?\\nThe Australian Journal of Hospital Pharmacy. 1997;27(2):126–131. doi: 10.1002/jppr1997272126 [CrossRef] [Google Scholar]60. \\nBautista S, Saggion H. Can Numerical Expressions Be Simpler?\\nImplementation and Demostration of a Numerical Simplification System for Spanish. In: LREC; 2014. p. 956–962. [Google Scholar]61. ISO/IEC. ISO/IEC DIS 23859-1 Information technology — User interfaces — Part 1: Guidance on making written text easy to read and easy to understand; 2022.62. Moreno L, Alarcon R, Martínez P. Designing and Evaluating a User Interface for People with Cognitive Disabilities. In: Proceedings of the XXI International Conference on Human Computer Interaction; 2021. p. 1–8.63. \\nPustejovsky J, Stubbs A. Natural Language Annotation for Machine Learning: A guide to corpus-building for applications. “O’Reilly Media, Inc.”; 2012. [Google Scholar]64. Yu CH, Miller RC. Enhancing web page readability for non-native readers. In: Proceedings of the sIGCHI conference on human factors in computing systems; 2010. p. 2523–2532.65. Alonzo O, Seita M, Glasser A, Huenerfauth M. Automatic text simplification tools for deaf and hard of hearing adults: Benefits of lexical simplification and providing users with autonomy. In: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems; 2020. p. 1–13.66. Shardlow M, Cooper M, Zampieri M. CompLex — A New Corpus for Lexical Complexity Prediction from Likert Scale Data. In: Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI). Marseille, France: European Language Resources Association; 2020. p. 57–62. Available from: https://aclanthology.org/2020.readi-1.9.67. \\nCambria E, White B. Jumping NLP Curves: A Review of Natural Language Processing Research. IEEE Computational Intelligence Magazine. 2014;9(2):48–57. doi: 10.1109/MCI.2014.2307227 [CrossRef] [Google Scholar]68. \\nHirschberg J, Manning CD. Advances in natural language processing. Science. 2015;349(6245):261–266. doi: 10.1126/science.aaa8685\\n [PubMed] [CrossRef] [Google Scholar]69. \\nGale WA, Church K, Yarowsky D. One sense per discourse. In: Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February; \\n23–26, 1992; 1992. [Google Scholar]70. \\nBayerl PS, Paul KI. What determines inter-coder agreement in manual annotations? A meta-analytic investigation. Computational Linguistics. 2011;37(4):699–725. doi: 10.1162/COLI_a_00074 [CrossRef] [Google Scholar]Table 1Text simplification resources for English/Spanish.ResourceAnnotated textSizeLanguage: English (EN) Spanish (ES)Annotation methodSimple English WikipediaA simplified version of regular Wikipedia183,000 content pages to dateENPages edited by 1,203 active usersSemEval 2012 [34]English Internet Corpus [35]2,010 instances of simplicity rankingsENNative English speakersLSeval [36]English Internet Corpus [35]430 instances of simplicity rankingsEN46 Amazon Mechanical Turk (turkers), 9 PHD studentsLexMTurk [37]Wikipedia500 instances with target complex words and simpler synonymsEN50 Turkish English speakingBenchLS [38]Compilation of LSeval and LexMTurk929 instances with an average of 7 candidates per complex wordENCorrected and filtered by English speakersNNSeval [39]Filtered version of BenchLS239 instancesENNon-native english speakersWikipedia—Simple WikipediaSimple English Wikipedia167,689 aligned sentencesENLanguage modelling [40]PWKP (WikiSmall) [41]Wikipedia and Simple Wikipedia108,016 aligned sentencesENStatistical machine translationSimplext [19]News texts200 aligned news textsESHuman editors trained in easy-to-read guidelinesSS Corpus [42]Wikipedia and Simple Wikipedia492,993 aligned sentencesENUnsupervised methodNewsela [28]News articlesParallel simple-complex articles with 11-grade levelsEN, ESManually produced by professional editorsRANLP 2017 [43]Wikipedia14,280 instances with target complex wordsEN, ES54 turkers (Native and non-native speakers)WikiLarge [44]WikiSmall, Aligned sentences pairs [40, 45]2,000 for dev, 359 for test, 296,402 for trainingENCombination of previously created simplification corporaPPDB-S/M [46]PPDB5,709 unigrams for S size, 15,524 unigrams for M sizeESBuilt by filtering and ordering paraphrases pairs from the paraphrases database (PPDB)CASSA [46]CASSA dataset5,640,694 5-gramsESGenerated by extracting all unique 5-grams pairs from CASSA resourceASSET [47]TurkCorpus extension23,590 human simplifications associated with 2,359 sentences from TurkCorpusENAmazon Mechanical TurkVYTEDU-CW) [48]Transcripts of academic videos9,175 words, 723 annotated as complexES430 annotators studentsALEXSIS [49]RANLP 2017 datasets381 instances with an average of 10.28 substitutes per instanceESprolific.co annotatorsOpen in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 1Open in a separate windowCorpus building methodology.Table 2An extract of the target/synonym dataset for human evaluation with Group 1 (people with mild intellectual disabilities) and Group 2 (older people).Target WordSynonymsConclusionEtiquetado (Labelling)Letrero (sign), inscripción (inscription), rótulo (banner)Explanation required for both groupsEtiqueta (formal/label)Ceremonia (ceremony), protocolo (protocol)Explanation required for Group 1Known Group 2Envasados (packaged)Empaquetados (packaging)Known by both groupsA granel (in bulk)Suelto (loose), sin envase (without packaging)Known for both groupsOn-line (Online)en línea (online), conectado a Internet (connected to the Internet)Known by Group 1Explanation required for Group 2Comensales (diners)Invitados (guests)Unknown by Group 1Known by Group 1Saludables (salubrious)Sanos (healthy), beneficiosos (beneficial)Explanation required for both groupsCopiosa (copious)Abundante (abundant)Unknown by both groupsCrudos (raw)sin cocinar (not cooked)Known by both groupsDenominación (denomination)Nombre (name)Explanation required for both groupsReclamar (claim)Demandar (sue), quejarse (complain), exigir (demand)Explanation required for both groupsIrregularidades (irregularities)Anomalía (anomaly), alteración (alteration), variación (variation)Unknown by both groupsÓptimas (optimum)Buenas (good), excelentes (excellent)Explanation required by both groupsEmbalaje (packaging)Envase (container), envoltorio (wrapping)Known for both groupsÍntegro (exhaustive)Entero (whole), completo (complete), intacto (intact)Known for both groupsConsumidor (consumer)Comprador (buyer/purchaser), cliente (client), usuario (user)Explanation required for Group 1Known Group 2Provisional (provisional)Temporales (temporary)Unknown for both groupsConsejo (Council)Asambleas (assembly), juntas (board), comisiones (commission/committee)Known for both groupsProporcionar (provide)Dar (give), proporcionar (provide)Known for both groupsCiudadanía (citizens)Sociedad (society), población (populace), nacionalidad (nationality)Known for both groupsVeraz (veracious)Real (real), cierta (certain), verdadera (true)Unknown by both groupsEficacia (efficiency)Utilidad (usefulness), efectividad (effectiveness)Unknown by both groupsContrastar (contrast)Comprobada (proven), comparada (compared), verificada (verified)Unknown for both groupsSoporte (base)Base (basis), fundamento (foundation), apoyo (support)Unknown for both groupsEvidencias (evidence)Certeza (certainty), seguridad (security), prueba (proof), demostración (demonstration)Known for both groupsOpen in a separate windowTable 3EASIER corpus statistics.EASIERDocuments260Sentences3,778Words134,528Average number of sentences per document15Average number of tokens per document517Total instances for CWI44,975Complex Words8,155Total instances for SG/SS5,130Proposed synonyms7,892Average of complex Words per document30Average of proposed synonyms per document29Complex Words with at least one substitute5,130Open in a separate windowTable 4EASIER corpus—CWI dataset results where N: nouns, V: verbs, A: adverbs, I: Interjections, PN: proper nouns, M: multi- words.POSTAGCohen’s Kappa (Rater 1–2)Cohen’s Kappa (Rater 1–3)Cohen’s Kappa (Rater 2–3)Fleiss Kappa\\nN\\n0.47500.41140.57110.484\\nV\\n0.40820.52180.43850.454\\nA\\n0.20110.19420.46400.31\\nI\\n0.50020.15450.26580.3\\nPN\\n0.22630.24410.53380.347\\nN—V\\n0.46670.43650.55860.487\\nN—V—A\\n0.46280.43740.56020.487\\nN—V—I\\n0.46890.43420.55590.486\\nN—V—I—PN\\n0.43300.42280.55300.471\\nN—V—M\\n0.64550.60790.67280.641\\nN—V—A—M\\n0.64220.60940.67390.641\\nN—V—I—M\\n0.64650.60600.67070.64\\nN—V—I—PN—M\\n0.60670.59260.65970.619Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 2Open in a separate windowAnnotations between annotator 2 and 3.Table 5Participant demographic information for corpus study (Group 1: Elder people, Group2: People with intellectual disabilities, Group 3: Control users).FeaturesGroup 1Group 2Group 3All participantsN = 15%N = 15%N = 15%N = 45%\\nAge\\n71+7(47)----7(16)45–708(53)4(27)3(20)15(33)34–44--5(33)5(33)10(22)33 or younger--6(40)7(47)13(29)\\nGender\\nMale7(47)6(40)8(53)21(47)Female8(53)9(60)7(47)24(53)\\nEducation (Highest completed)\\nNone1(7)2(13)--3(7)Primary school5(33)7(47)--12(27)High school9(60)6(40)5(33)20(44)University education----10(67)10(22)\\nReading experience (books per year)\\nNone3(20)9(60)3(20)15(33)1–35(33)3(20)6(40)14(31)3–64(27)1(7)4(27)9(20)6–123(20)2(13)1(7)6(13)12+----1(7)1(2)Open in a separate windowTable 6Result metrics for both groups in Task 1 where ID = User Id, AC = Acuraccy, PR = Precision and Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\nGROUP 1\\n\\nGROUP 2\\n\\nGROUP 3\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n10.570.780.520.40160.560.520.650.40310.560.520.590.4220.580.780.530.42170.630.590.770.54320.600.550.730.4730.680.740.650.63180.600.550.730.47330.590.550.730.4640.770.800.750.75190.590.550.690.47340.590.540.710.4450.700.740.680.67200.610.570.700.51350.590.550.730.4660.610.700.570.51210.590.560.580.53360.560.510.780.3770.580.780.530.42220.650.610.700.58370.710.700.720.7080.560.780.510.37230.590.560.600.53380.580.530.780.4290.590.680.540.45240.650.610.770.56390.570.520.680.42100.560.580.510.40250.650.610.750.57400.550.500.530.37110.630.800.580.52260.660.620.780.58410.630.590.700.54120.590.650.540.46270.640.610.690.58420.590.540.790.43130.530.510.510.48280.670.640.750.62430.560.520.650.40140.560.780.510.37290.650.610.770.56440.630.590.770.54150.630.730.590.53300.620.590.650.56450.590.540.710.44\\nGROUP 1 SCORES\\n\\nGROUP 2 SCORES\\n\\nGROUP 3 SCORES\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\n\\nID\\n\\nAC\\n\\nPR\\n\\nRC\\n\\nF-1\\nALL0.610.570.680.51ALL0.620.590.690.54ALL0.590.550.690.47\\nOVERALL SCORE\\n\\nACURACCY\\n\\nPRECISION\\n\\nRECALL\\n\\nF1\\n0.610.570.690.51Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 3Open in a separate windowPrecision scores among every participant divided into groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 4Open in a separate windowRecall scores among every participant divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.PLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 5Open in a separate windowNumber of detected complex words, divided by groups, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.Table 7Task2: Number of cases where at least one candidate, two candidates and all candidates were ranked as correct, sorted by groups and sentences where Grp 1: older people, Grp 2: people with intellectual disabilities and Grp 3: control users.At least one candidate ranked as correctAt least two candidates ranked as correctAll candidates ranked as correctSentence-IDGrp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)Grp 1 (N:15)Grp 2 (N:15)Grp 3 (N:15)S1151515111213795S21515148107773S31515141099884S4151515121012878S51415141211108105S61515151111141199S7141514101110872S814151310115782S9151414111011875S1015151513121110105S111514141211131086S121515151211131097S1314151410107984S141515139118954S151514141169953\\nMEAN\\n14.7314.8014.2010.8010.4010.138.67.84.8\\nACCEPTANCE (%)\\n989995726968575232Open in a separate windowPLoS One. 2023; 18(4): e0283622. Published online 2023 Apr 12.  doi:\\xa010.1371/journal.pone.0283622Copyright/LicenseRequest permission to reuseCopyright © 2023 Alarcon et alThis is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.Fig 6Open in a separate windowNumber of instances where at least one substitute was taken as correct of incorrect, divided by group and education level, where Group 1: older people, Group 2: people with intellectual disabilities and Group 3: control users.\\n\\n\\n\\n\\n', metadata={'source': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader', 'title': 'EASIER corpus: A lexical simplification resource for people with cognitive impairments', 'language': 'en'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b45a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"(?<=\\. )\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98e59f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1116, which is longer than the specified 1000\n",
      "Created a chunk of size 1629, which is longer than the specified 1000\n",
      "Created a chunk of size 1707, which is longer than the specified 1000\n",
      "Created a chunk of size 2354, which is longer than the specified 1000\n",
      "Created a chunk of size 4014, which is longer than the specified 1000\n",
      "Created a chunk of size 2479, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "docsv2=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbfcf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a3ee534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54041605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"(?<=\\. )\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9724aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef422042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e97226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # load documents\n",
    "    loader = WebBaseLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    #text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs=text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb748273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self,  **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader\"\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "    \n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer'] \n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=600, style={'background-color': '#F6F6F6'}))\n",
    "        ])\n",
    "        inp.value = ''  #clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels,scroll=True)\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query :\n",
    "            return pn.Column(\n",
    "                pn.Row(pn.pane.Markdown(f\"Last question to DB:\", styles={'background-color': '#F6F6F6'})),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={'background-color': '#F6F6F6'})),\n",
    "            pn.pane.Str(self.db_query )\n",
    "        )\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return \n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends('convchain', 'clr_history') \n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n",
    "        rlist=[pn.Row(pn.pane.Markdown(f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self,count=0):\n",
    "        self.chat_history = []\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcaf5e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1116, which is longer than the specified 1000\n",
      "Created a chunk of size 1629, which is longer than the specified 1000\n",
      "Created a chunk of size 1707, which is longer than the specified 1000\n",
      "Created a chunk of size 2354, which is longer than the specified 1000\n",
      "Created a chunk of size 4014, which is longer than the specified 1000\n",
      "Created a chunk of size 2479, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept='.pdf')\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type='warning')\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput( placeholder='Enter text here…')\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp) \n",
    "\n",
    "jpg_pane = pn.pane.Image( './img/convchain.jpg')\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation,  loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2= pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources ),\n",
    ")\n",
    "tab3= pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4=pn.Column(\n",
    "    pn.Row( file_input, button_load, bound_button_load),\n",
    "    pn.Row( button_clearhistory, pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\" )),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400))\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n",
    "    pn.Tabs(('Conversation', tab1), ('Database', tab2), ('Chat History', tab3),('Configure', tab4))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d6fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.1.0/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.1.0/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.1.0/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.1.0/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(> .cell-output-ipywidget-background\n",
       "    > .lm-Widget\n",
       "    > *[data-root-id]),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='60f49cfd-db1d-4dcc-a273-9b5f2c60aa21'>\n",
       "  <div id=\"fbc0121c-690d-4b63-9657-99923f30bc65\" data-root-id=\"60f49cfd-db1d-4dcc-a273-9b5f2c60aa21\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ff119713-bd4d-4d7f-abf9-c781f69d959a\":{\"version\":\"3.1.1\",\"title\":\"Bokeh Application\",\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}],\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"60f49cfd-db1d-4dcc-a273-9b5f2c60aa21\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"911efff1-d012-4bad-9437-b2c1434cb1a8\",\"attributes\":{\"plot_id\":\"60f49cfd-db1d-4dcc-a273-9b5f2c60aa21\",\"comm_id\":\"d1193417c5524c4abdaba38df2adf1ba\",\"client_comm_id\":\"5f35fde60b5d426d83ddde5cf1f944ad\"}}],\"callbacks\":{\"type\":\"map\"}}};\n",
       "  var render_items = [{\"docid\":\"ff119713-bd4d-4d7f-abf9-c781f69d959a\",\"roots\":{\"60f49cfd-db1d-4dcc-a273-9b5f2c60aa21\":\"fbc0121c-690d-4b63-9657-99923f30bc65\"},\"root_ids\":[\"60f49cfd-db1d-4dcc-a273-9b5f2c60aa21\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "60f49cfd-db1d-4dcc-a273-9b5f2c60aa21"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "860cb2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='34c527b3-478f-4ba4-a18b-72f8586cd5cc'>\n",
       "  <div id=\"a1c6e1b5-ab65-4fa1-a083-e5a07236086e\" data-root-id=\"34c527b3-478f-4ba4-a18b-72f8586cd5cc\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"333c859d-7e01-4c35-ada3-827e977cf7ed\":{\"version\":\"3.1.1\",\"title\":\"Bokeh Application\",\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}],\"roots\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"34c527b3-478f-4ba4-a18b-72f8586cd5cc\",\"attributes\":{\"name\":\"Column01424\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/bundled/theme/native.css\"}}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"67871a13-9a00-4057-bf35-b9347f2074ae\",\"attributes\":{\"name\":\"Row01418\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"1cce5e1a-377f-4617-bd16-99ab47816def\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/markdown.css\"}},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;h1 id=&quot;chatwithyourdata_bot-2&quot;&gt;ChatWithYourData_Bot &lt;a class=&quot;header-anchor&quot; href=&quot;#chatwithyourdata_bot-2&quot;&gt;\\u00b6&lt;/a&gt;&lt;/h1&gt;\\n\"}}]}},{\"type\":\"object\",\"name\":\"panel.models.tabs.Tabs\",\"id\":\"c71001c3-71db-4893-8ce1-9724fa7df95b\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"tabs\":[{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"ed9cc832-2ba3-4c14-92f1-57ff9fdfc71d\",\"attributes\":{\"name\":\"Column01259\",\"title\":\"Conversation\",\"child\":{\"type\":\"object\",\"name\":\"Column\",\"id\":\"e41113ee-3585-429f-b31c-33097b45a08f\",\"attributes\":{\"name\":\"Column01259\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"3211b173-1376-45b7-b133-1fe9a350b8dd\",\"attributes\":{\"name\":\"Row01213\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"TextInput\",\"id\":\"7eeccc1f-792b-4e70-9054-b8fd620224ae\",\"attributes\":{\"js_property_callbacks\":{\"type\":\"map\",\"entries\":[[\"change:value\",[{\"type\":\"object\",\"name\":\"CustomJS\",\"id\":\"a0128549-8fd7-4e6d-bcaf-72ef3a5c2ab7\",\"attributes\":{\"tags\":[[140515487065872,[null,\"value\"],[null,\"loading\"]]],\"args\":{\"type\":\"map\",\"entries\":[[\"bidirectional\",false],[\"properties\",{\"type\":\"map\",\"entries\":[[\"value\",\"loading\"]]}],[\"source\",{\"id\":\"7eeccc1f-792b-4e70-9054-b8fd620224ae\"}],[\"target\",{\"type\":\"object\",\"name\":\"Row\",\"id\":\"8fd25d99-d910-48e2-a136-23b399408bca\",\"attributes\":{\"name\":\"Row01231\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"height\":300,\"min_height\":300,\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"c3a8a9b5-e8dd-4fbd-a652-a968632d2773\",\"attributes\":{\"name\":\"WidgetBox01250\",\"css_classes\":[\"panel-widget-box\",\"scrollable\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"72d363af-1632-4ac0-ae89-69a063867ec4\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/widgetbox.css\"}},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"a09038cf-8b7c-4cef-811c-5d3a097674a4\",\"attributes\":{\"name\":\"Row01247\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"72d3cf04-607a-4f9c-8e83-c7dacc116ad8\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;p&gt;User:&lt;/p&gt;\\n\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"ebf8a583-cf94-47d0-a303-bcdbf256460c\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"width\":600,\"min_width\":600,\"margin\":[5,10],\"align\":\"start\"}}]}}]}}]}}]]},\"code\":\"\\n    if ('value'.startsWith('event:')) {\\n      var value = true\\n    } else {\\n      var value = source['value'];\\n      value = value;\\n    }\\n    if (typeof value !== 'boolean' || source.labels !== ['Loading']) {\\n      value = true\\n    }\\n    var css_classes = target.css_classes.slice()\\n    var loading_css = ['pn-loading', 'pn-arc']\\n    if (value) {\\n      for (var css of loading_css) {\\n        if (!(css in css_classes)) {\\n          css_classes.push(css)\\n        }\\n      }\\n    } else {\\n     for (var css of loading_css) {\\n        var index = css_classes.indexOf(css)\\n        if (index > -1) {\\n          css_classes.splice(index, 1)\\n        }\\n      }\\n    }\\n    target['css_classes'] = css_classes\\n    \"}}]]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"width\":300,\"min_width\":300,\"margin\":[5,10],\"align\":\"start\",\"placeholder\":\"Enter text here\\u2026\",\"max_length\":5000}}]}},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"127ac5bc-cf6d-4fe2-92f6-793ebe0fc36a\",\"attributes\":{\"name\":\"Divider01216\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"ad6c56d1-22ed-4041-bc82-479990900bfd\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"a58afed0-a8f4-4148-9a19-9f7d4d02be59\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}},{\"id\":\"8fd25d99-d910-48e2-a136-23b399408bca\"},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"9605d167-decc-45b8-8d7d-7fcfe5ae585d\",\"attributes\":{\"name\":\"Divider01256\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"bba025c4-9184-4bbb-a810-93dbd68c3b39\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"a6e75351-2c42-4a57-a3c9-53a7faf9fd25\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}}]}}}},{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"8352458c-996c-4f7a-ad85-1221b39474ad\",\"attributes\":{\"name\":\"Column01319\",\"title\":\"Database\",\"child\":{\"type\":\"object\",\"name\":\"Column\",\"id\":\"65344def-03f7-465c-97b0-013df81d6b8f\",\"attributes\":{\"name\":\"Column01319\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"36c0036e-391a-46fd-93b3-2cda27acb3de\",\"attributes\":{\"name\":\"Row01274\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"14a4ca61-53d1-411d-955e-255dfb7d3893\",\"attributes\":{\"name\":\"Column01295\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"40db7905-829d-4afe-b5b5-e2bffe45e19a\",\"attributes\":{\"name\":\"Row01283\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"acdf9c4f-64bb-4d32-b5d4-860665d0442e\",\"attributes\":{\"css_classes\":[\"markdown\"],\"styles\":{\"type\":\"map\",\"entries\":[[\"background-color\",\"#F6F6F6\"]]},\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;p&gt;Last question to DB:&lt;/p&gt;\\n\"}}]}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"2d159db7-f57d-4172-9c2e-14c1077ea19f\",\"attributes\":{\"name\":\"Row01292\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"c20216b8-df83-4449-8ebc-84c4c94bceab\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;no DB accesses so far&lt;/pre&gt;\"}}]}}]}}]}},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"acd45fac-82ee-49e1-9e69-a2b7d0e16362\",\"attributes\":{\"name\":\"Divider01301\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"0470db46-d0a8-49c4-82b3-f22c41feb077\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"db77a787-f208-4313-bbb9-a402c8cf00ee\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"1a644d68-c724-4ad8-83bc-3334a88affb2\",\"attributes\":{\"name\":\"Row01316\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"ceb4867d-dbf7-4147-8f67-5952acff3f3e\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt; &lt;/pre&gt;\"}}]}}]}}}},{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"00d9f2c4-9c0b-4f04-97cf-5e7225bfdb2a\",\"attributes\":{\"name\":\"Column01355\",\"title\":\"Chat History\",\"child\":{\"type\":\"object\",\"name\":\"Column\",\"id\":\"3259909b-9a2c-4cb2-ad38-8e76461507de\",\"attributes\":{\"name\":\"Column01355\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"14e84f82-2e93-44be-a3de-0756f0380363\",\"attributes\":{\"name\":\"Row01334\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Column\",\"id\":\"4894246a-45d6-4146-846f-35ba789cf8dc\",\"attributes\":{\"name\":\"WidgetBox01346\",\"css_classes\":[\"panel-widget-box\",\"scrollable\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"72d363af-1632-4ac0-ae89-69a063867ec4\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"width\":600,\"min_width\":600,\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"9448bc51-a426-4fcc-baa4-ee7e25704dc0\",\"attributes\":{\"name\":\"Row01343\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"a361589a-8d39-44a5-88a4-c58adc2b137b\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;pre&gt;No History Yet&lt;/pre&gt;\"}}]}}]}}]}},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"2e8418f0-f9ee-4d46-8de9-a724e2cfb783\",\"attributes\":{\"name\":\"Divider01352\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"94ef2f6c-9d50-415c-b0a1-7efb8c52e154\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"eea2e6d7-3060-4f2f-8265-eece7dbb4572\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}}]}}}},{\"type\":\"object\",\"name\":\"TabPanel\",\"id\":\"b24829ef-5d90-4cb3-8041-99568e9193c6\",\"attributes\":{\"name\":\"Column01409\",\"title\":\"Configure\",\"child\":{\"type\":\"object\",\"name\":\"Column\",\"id\":\"07536617-bb69-42a6-97e9-dedd5464436a\",\"attributes\":{\"name\":\"Column01409\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"5c3dbceb-a437-40b1-80f1-ae23321dddf0\",\"attributes\":{\"name\":\"Row01385\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"FileInput\",\"id\":\"c4d12e68-2165-42bd-914d-3a388185cdd3\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"accept\":\".pdf\"}},{\"type\":\"object\",\"name\":\"Button\",\"id\":\"aba5e5ad-0bc4-4f11-aedd-bdb6f182f21e\",\"attributes\":{\"button_type\":\"primary\",\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"acf4ed49-9cd2-4129-9c4b-411a09202703\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/button.css\"}},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"label\":\"Load DB\"}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"a59869f0-61d9-4346-af2d-bbbb5f68a06d\",\"attributes\":{\"name\":\"Row01370\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"0c7e74b1-7494-409f-8aab-f2c6e03a3391\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;p&gt;Loaded File: &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader&quot;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096182/?report=reader&lt;/a&gt;&lt;/p&gt;\\n\"}}]}}]}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"840dda88-9276-460e-bffa-40b11ab92c06\",\"attributes\":{\"name\":\"Row01394\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Button\",\"id\":\"bd56ebac-3dac-4cd1-9c87-30752894397b\",\"attributes\":{\"button_type\":\"warning\",\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"acf4ed49-9cd2-4129-9c4b-411a09202703\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"label\":\"Clear History\"}},{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"6fa4b03a-3d69-4fd6-b0c0-97886b9d77a0\",\"attributes\":{\"css_classes\":[\"markdown\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"cb1b254d-2791-413b-963a-3c51a7ac0bbe\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;p&gt;Clears chat history. Can use to start a new topic&lt;/p&gt;\\n\"}}]}},{\"type\":\"object\",\"name\":\"Div\",\"id\":\"8cbd3520-142a-4ead-9cbb-7e015c7285b3\",\"attributes\":{\"name\":\"Divider01397\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"81535241-2b82-4d08-87ff-bd5327f0a640\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"9adac2ce-4b2e-4628-bffe-5a7218e71760\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.1.0/dist/css/divider.css\"}}],\"margin\":0,\"width_policy\":\"fit\",\"align\":\"start\",\"text\":\"<hr>\"}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"07c2fd57-d3fc-4e90-bfbc-825673e8b0b9\",\"attributes\":{\"name\":\"Row01406\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"e714b451-db5f-4c4b-aa79-f6de91ff42b9\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"margin\":0,\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"d33953e3-30d6-4cd5-a9d4-9b2e5b91d4b1\",\"attributes\":{\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"9f29f619-a51f-4af7-9c3c-48f2c7e77c70\"},{\"id\":\"512dfe22-9919-4cc0-a0b3-74a905fbb253\"},{\"id\":\"ea53bb4e-980b-4879-9443-39b78ead7a6e\"}],\"width\":400,\"min_width\":400,\"margin\":[5,10],\"align\":\"start\",\"text\":\"&lt;img src=&quot;./img/convchain.jpg&quot;  style=&quot;max-width: 100%; max-height: 100%; object-fit: contain; width: 400px; height: auto;&quot;&gt;&lt;/img&gt;\"}}]}}]}}}}]}}]}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"ca4b908e-0256-4796-b5b0-eaaa689315d2\",\"attributes\":{\"plot_id\":\"34c527b3-478f-4ba4-a18b-72f8586cd5cc\",\"comm_id\":\"1f29b5e3efa64fd9aa72ccada11d9ff9\",\"client_comm_id\":\"bd1f37bd9f9345249742ff607f111daf\"}}],\"callbacks\":{\"type\":\"map\"}}};\n",
       "  var render_items = [{\"docid\":\"333c859d-7e01-4c35-ada3-827e977cf7ed\",\"roots\":{\"34c527b3-478f-4ba4-a18b-72f8586cd5cc\":\"a1c6e1b5-ab65-4fa1-a083-e5a07236086e\"},\"root_ids\":[\"34c527b3-478f-4ba4-a18b-72f8586cd5cc\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Column\n",
       "    [0] Row\n",
       "        [0] Markdown(str)\n",
       "    [1] Tabs\n",
       "        [0] Column\n",
       "            [0] Row\n",
       "                [0] TextInput(placeholder='Enter text here…')\n",
       "            [1] Divider()\n",
       "            [2] ParamFunction(function, _pane=WidgetBox, height=300, loading_indicator=True)\n",
       "            [3] Divider()\n",
       "        [1] Column\n",
       "            [0] ParamMethod(method, _pane=Column)\n",
       "            [1] Divider()\n",
       "            [2] ParamMethod(method, _pane=Str)\n",
       "        [2] Column\n",
       "            [0] ParamMethod(method, _pane=WidgetBox)\n",
       "            [1] Divider()\n",
       "        [3] Column\n",
       "            [0] Row\n",
       "                [0] FileInput(accept='.pdf')\n",
       "                [1] Button(button_type='primary', name='Load DB')\n",
       "                [2] ParamFunction(function, _pane=Markdown)\n",
       "            [1] Row\n",
       "                [0] Button(button_type='warning', name='Clear History')\n",
       "                [1] Markdown(str)\n",
       "            [2] Divider()\n",
       "            [3] Row\n",
       "                [0] Image(str, width=400)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "34c527b3-478f-4ba4-a18b-72f8586cd5cc"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
